{"meta":{"title":"开普勒鑫球","subtitle":null,"description":"dapper talos","author":"开普勒鑫球","url":"http://kplxq.github.io"},"pages":[{"title":"关于我们","date":"2018-01-06T09:48:39.942Z","updated":"2018-01-06T09:48:39.942Z","comments":true,"path":"about/index.html","permalink":"http://kplxq.github.io/about/index.html","excerpt":"","text":"开普勒鑫球是一个开放式的技术团体，是新金融科技的先行者。我们将探索金融科技发展，用新科技打造新金融，通过技术孵化、知识分享、项目开源，与业界同行共进。 开源项目 Talos github gitee QQ交流群：637375352 微信群：请联系管理员加入 微信公众号： 官方社区：www.kplxq.com"},{"title":"Tags","date":"2017-12-21T14:20:50.796Z","updated":"2017-12-21T14:20:50.796Z","comments":true,"path":"tags/index.html","permalink":"http://kplxq.github.io/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2017-12-21T14:20:50.796Z","updated":"2017-12-21T14:20:50.796Z","comments":true,"path":"categories/index.html","permalink":"http://kplxq.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"怎样监控Kubernetes容器","slug":"怎样监控Kubernetes容器","date":"2018-01-17T03:53:50.000Z","updated":"2018-01-19T04:47:23.083Z","comments":true,"path":"2018/01/17/怎样监控Kubernetes容器/","link":"","permalink":"http://kplxq.github.io/2018/01/17/怎样监控Kubernetes容器/","excerpt":"怎样监控Kubernetes容器一、容器的运行方式与VM和HOST的差异Kubernetes是现在最流行的容器编排系统，容器与VM和HOST有着显著不同。怎样对k8s平台上的容器进行监控？首先需要注意容器的运行方式与VM和HOST的不同：","text":"怎样监控Kubernetes容器一、容器的运行方式与VM和HOST的差异Kubernetes是现在最流行的容器编排系统，容器与VM和HOST有着显著不同。怎样对k8s平台上的容器进行监控？首先需要注意容器的运行方式与VM和HOST的不同： 运行实例从宏观层面迁移到微观层面容器运行在私有网络中，通常情况下与外部网络隔离。怎样从外部网络进入到容器私有网络、获取容器的监控数据？ 运行实例从静态、长生命周期转变成动态、短生命周期HOST和VM一般是静态IP地址，一旦开机、长期运行。而容器的IP是动态分配的，其创建、销毁、扩容、缩容非常频繁。如何及时发现新创建的容器、获取到它们的监控数据、并在仪表盘上恰当的展现出来？ 二、容器监控方案概述为了解决上述问题，kubernetes、promethues、influxdata等开源组织相继发布了一些容器监控工具和方案。例如：kubernetes 的 heapster+influxdb+grafana，prometheus的prometheus+alertmanager，influxdata的telegraf+influxdb+kapacitor。 我采用的是第一种，即： heapster+influxdb+grafana，实现简单、效果较好。 其中，heapster是k8s容器状态的收集、导出工具，influxdb是一种时序数据库，grafana是一种数据展示和报警系统。 heapster能导出当前时间点的所有容器的状态信息，解决了容器监控信息的采集和导出问题；grafana是功能强大的数据展示和报警工具，它的展示系统支持变量、模板、正则匹配、标签等功能，能把瞬息万变的容器信息有效组织、展示出来，报警系统支持多种方式、还可以基于webhook自己开发，实现短信报警等功能。 三、容器监控部署概述（由于字数限制，不详述，具体请参考官方文档；所有组件都基于容器部署） 部署influxdbhttps://github.com/influxdata/influxdb 部署heapsterhttps://github.com/kubernetes/heapster/tree/master/deploycommand加sink参数，包含influxdb的地址、用户名、密码，例如：–sink=influxdb:http://influxdb.default:8086?db=heapster&amp;user=heapster&amp;pw=1234 部署grafanahttps://github.com/grafana/grafana部署后请设置数据源datasource，加入influxdb。 四、设置仪表盘Grafana的仪表盘也就是监控数据的展示界面，可以自己设计，还可以导出共享给别人。我设计了一个容器监控的仪表盘，共享在grafana网站上，地址是：https://grafana.com/dashboards/3649 在namespace下拉框可以选择k8s容器的命名空间，在pod_name下拉框可以选择容器的匹配名称（前面几个字符或者全名都可以）。 五、建立容器报警我共享的仪表盘含有两个变量：namespace和pod_name，这样的仪表盘叫：模板。Grafana目前不支持在模板里创建报警。为了创建报警，我们需要再建一个不带变量的仪表盘，然后在时序图的Alert菜单里设置报警，设置报警阀值、通道、内容等信息： 六、建立报警一览图Grafana自带一个报警管理页面： 我们可以设计一个更清楚的报警一览图，可参考我共享的模板，地址是：https://grafana.com/dashboards/3489","categories":[],"tags":[],"keywords":[]},{"title":"机器人编程大赛的沙盒源代码正式开放提供下载啦！","slug":"机器人编程大赛的沙盒源代码正式开放提供下载啦！","date":"2018-01-15T08:25:12.000Z","updated":"2018-01-16T09:17:45.969Z","comments":true,"path":"2018/01/15/机器人编程大赛的沙盒源代码正式开放提供下载啦！/","link":"","permalink":"http://kplxq.github.io/2018/01/15/机器人编程大赛的沙盒源代码正式开放提供下载啦！/","excerpt":"怎样才能搞一个又有趣又能提升技术能力的活动？程序员年底团建怎么搞？想搞编程大赛，没有好的方案，没有沙盒？","text":"怎样才能搞一个又有趣又能提升技术能力的活动？程序员年底团建怎么搞？想搞编程大赛，没有好的方案，没有沙盒？ 开普勒鑫球杯机器人编程大赛的沙盒源代码（V1.0）正式对外开放，提供下载啦。 用你的思想控制硝烟弥漫的战场，利用牛逼的算法，牛逼的策略，创造属于你自己的无敌机器人！抢血包！躲地雷！群战！看看究竟谁才是You Xi Zhi King吧！ 在2.0版本的沙盒中，还支持多人PK、组队PK模式，支持传送门、天神下凡、凌波微步等多种更为先进的技能噢，后续也会开放源码，尽情继续关注。 QQ交流群：637375352微信公众号回复“机器人”，即可获取源代码地址。 参考阅读：玩游戏的逆天新姿势，屌炸天啊！！","categories":[],"tags":[{"name":"机器人编程","slug":"机器人编程","permalink":"http://kplxq.github.io/tags/机器人编程/"}],"keywords":[]},{"title":"玩游戏的逆天新姿势，屌炸天啊！！","slug":"玩游戏的逆天新姿势，屌炸天啊！！","date":"2018-01-12T08:24:44.000Z","updated":"2018-01-16T09:18:19.397Z","comments":true,"path":"2018/01/12/玩游戏的逆天新姿势，屌炸天啊！！/","link":"","permalink":"http://kplxq.github.io/2018/01/12/玩游戏的逆天新姿势，屌炸天啊！！/","excerpt":"打游戏，可以有很多姿势，比如下面这样的：","text":"打游戏，可以有很多姿势，比如下面这样的： 但对于程序员来说，这些还是太低级太Low啊，有本事，有本事你不要用手啊！！！你不要用手啊！！！不用手啊！！！手啊！！！啊！！！叮~叮~叮~ 就是下面酱紫滴！开普勒鑫球杯机器人大战编程竞赛，用你的思想控制硝烟弥漫的战场，利用牛逼的算法，牛逼的策略，创造属于你自己的无敌机器人！抢血包！躲地雷！群战！1月17日，现场PK，看看究竟谁才是You Xi Zhi King，参加还有大奖拿噢，是不是很兴奋！！！！ 最最重要的是，下周一（01月15号），我们还会开放机器人挑战赛沙盒的 源 代 码，一起来群P啊！敬请关注！（现场比赛暂时只限内部，欢迎关注开普勒鑫球，后续还有更多有趣的活动，还有福利拿噢）","categories":[],"tags":[{"name":"机器人编程","slug":"机器人编程","permalink":"http://kplxq.github.io/tags/机器人编程/"}],"keywords":[]},{"title":"从一段臭名昭彰却又广为人知的代码说起……","slug":"从一段臭名昭彰却又广为人知的代码说起……","date":"2018-01-10T08:24:26.000Z","updated":"2018-01-16T09:18:42.081Z","comments":true,"path":"2018/01/10/从一段臭名昭彰却又广为人知的代码说起……/","link":"","permalink":"http://kplxq.github.io/2018/01/10/从一段臭名昭彰却又广为人知的代码说起……/","excerpt":"作为一名程序猿，谁没挖过几个坑，坑坑都是泪啊…… ，农历年的年底了，鸡年要走了，狗年要来了，各位码工动代码时千万悠着点，三思而后行，可不能鸡飞狗跳啊！2018年，愿世界和平，天下无坑！今天就来和大家聊聊一个简单的并发编程的坑，","text":"作为一名程序猿，谁没挖过几个坑，坑坑都是泪啊…… ，农历年的年底了，鸡年要走了，狗年要来了，各位码工动代码时千万悠着点，三思而后行，可不能鸡飞狗跳啊！2018年，愿世界和平，天下无坑！今天就来和大家聊聊一个简单的并发编程的坑， 各位编码过程中，遇到过什么坑，欢迎留言，交流分享！","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://kplxq.github.io/tags/并发编程/"}],"keywords":[]},{"title":"开普勒鑫球全链路监控系统Talos正式开源","slug":"开普勒鑫球全链路监控系统Talos正式开源","date":"2017-12-15T15:17:13.000Z","updated":"2018-01-06T11:36:45.688Z","comments":true,"path":"2017/12/15/开普勒鑫球全链路监控系统Talos正式开源/","link":"","permalink":"http://kplxq.github.io/2017/12/15/开普勒鑫球全链路监控系统Talos正式开源/","excerpt":"2017年12月24日，开普勒鑫球的开源社区正式对外发布了其首个开源项目- Talos。","text":"2017年12月24日，开普勒鑫球的开源社区正式对外发布了其首个开源项目- Talos。 Talos是一个大数据全链路监控系统，由开鑫金服科技团队自主研发，供业界下载使用。开鑫金服科技团队期望通过这种开源的方式促进行业交流、发展，共同进步。 Talos以Google Dapper论文为理论基础，参照Twitter Brave的实现方案，面向当今互联网复杂的环境，基于客户端探针上报应用调用链相关日志，通过ElasticSearch引擎和HBase大数据存储技术，对海量请求进行实时链式跟踪、预警，能快速定位问题根源，有效保障了系统的稳定运行，提升了客户体验。 开鑫金服科技团队通过5年的磨砺，自主研发了多项先进的框架和平台。2017年12月24日，开鑫金服公司成立5周年，为迎接这有意义的一天，团队决定将Talos项目贡献给开普勒鑫球的开源社区；同时也期望更多的技术爱好者加入到开源社区中来，共同分享、交流。开普勒鑫球开源社区后续还会开源更多优质领先的项目，敬请期待！ 开源地址（或点击开普勒鑫球公众号菜单【开源项目】直接访问）：","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"如何设计一个大数据全链路监控系统","slug":"【纯干货分享】如何设计一个大数据全链路监控系统","date":"2017-12-15T15:07:13.000Z","updated":"2018-01-06T11:37:31.032Z","comments":true,"path":"2017/12/15/【纯干货分享】如何设计一个大数据全链路监控系统/","link":"","permalink":"http://kplxq.github.io/2017/12/15/【纯干货分享】如何设计一个大数据全链路监控系统/","excerpt":"纯干货分享！ 大数据全链路监控系统架构设计内部PPT来啦，赶紧保存。 后续开普勒鑫球还会陆续发布一系列文章逐一展开详细讲解，手把手教你，干货满满，敬请关注吧！","text":"纯干货分享！ 大数据全链路监控系统架构设计内部PPT来啦，赶紧保存。 后续开普勒鑫球还会陆续发布一系列文章逐一展开详细讲解，手把手教你，干货满满，敬请关注吧！","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"部署文档","slug":"部署文档","date":"2017-12-15T14:59:56.000Z","updated":"2017-12-22T10:00:06.488Z","comments":true,"path":"2017/12/15/部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/部署文档/","excerpt":"整体部署架构","text":"整体部署架构 部署节点数及基准配置 组件名称 组件类型 建议节点数 基准配置 搜索引擎(elastic search) 中间件 Elastic Search(3) cpu:2C memory:8G 分布式列存储数据库(Hbase) 中间件 CDH Manager(1) cpu:2C memory:4G disk:50G 分布式列存储数据库(Hbase) 中间件 Hbase MasterServer(1) cpu:2C memory:4G disk:50G 分布式列存储数据库(Hbase) 中间件 Hbase RegionServer(2) cpu:2C memory:4G disk:150G(留存30天数据) 分布式队列服务器(Kafka) 中间件 Kafka Server(3) cpu:2C memory:4G disk:20G 分布式配置管理服务器(zookeeper) 中间件 Zookeeper Server(3) cpu:2C memory:4G talos-storage 自有组件 2 cpu:2C memory:4G disk:20G talos-dashboard 自有组件 1 cpu:2C memory:4G disk:20G 部署步骤hosts配置在部署前请维护整个集群环境的hosts，并推送到每个部署节点 12345678910111213141516171819202122#es 集群192.168.99.101 es1192.168.99.102 es2192.168.99.103 es3# kafka集群192.168.99.104 kafka1 zk1192.168.99.105 kafka2 zk2192.168.99.106 kafka3 zk3# hbase集群192.168.99.107 hbase1192.168.99.108 hbase2192.168.99.109 hbase3192.168.99.110 cdhmaster# talos-dashboard192.168.99.111 talos-dashboard# talos-storage192.168.99.112 talos-storage1192.168.99.113 talos-storage2 中间件安装中间件版本信息如下: 中间件名称 版本 备注 搜索引擎 Elastic Search-2.4.0 3个节点 分布式列存储数据库 Hbase-1.2.0(CDH-5.8.0) 4个节点 CDH Manager(1) Hbase MasterServer() Hbase RegionServer(2) 分布式队列服务器 Kafka-2.11-0.10.0.1 3个节点 分布式文件系统 Hdfs-2.6.0(CDH-5.8.0) 内嵌至Hbase部署中 分布式配置管理服务器 Zookeeper-3.4.5(CDH-5.8.0) - Kafka1、中间件安装另附文档Kafka部署文档2、创建Talos系统在kafka集群所用的topic 配置如下： topic名称：talos-open-sourcepartition数目：1024replication数据：1 (无需备份) 脚本如下： 1./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1024 --topic talos-open-source Elasticsearch1、中间件安装另附文档Elasticsearch部署文档2、创建Talos系统elasticsearch索引 配置如下：index： talosmapping: trace刷新时间：5s分片数：5备份：0 123456789101112131415curl -XPOST http://es1:9200/talos -d &apos;&#123; &quot;settings&quot; : &#123; &quot;number_of_replicas&quot;: &quot;0&quot;, &quot;number_of_shards&quot;: &quot;5&quot;, &quot;refresh_interval&quot;: &quot;5s&quot; &#125;, &quot;mappings&quot; : &#123; &quot;trace&quot; : &#123; &quot;properties&quot; : &#123; &quot;traceid&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot; &#125;, &quot;contents&quot; : &#123; &quot;type&quot; : &quot;string&quot;&#125; &#125; &#125; &#125;&#125;&apos; HBase1、中间件安装参考HBase部署文档2、创建Talos系统Hbase表 配置如下：表名：tracerowkey: id （talos系统中的traceId)列族：span （talos系统中的不同的spanId即为该列族下的不同列）数据失效时间：30天 脚本如下（在hbase shell中执行）： 1create &apos;trace&apos;, &#123;NAME=&gt;&apos;id&apos;, TTL=&gt;&apos;2592000&apos;&#125;,&#123;NAME=&gt;&apos;span&apos;, TTL=&gt;&apos;2592000&apos;&#125; 系统自有组件安装talos-dashboard部署前请确认hosts已更新 1、下载talos-dashboard.war2、将talos-dashboard包放到tomcat/webapps路径下3、启动tomcat4、浏览器打开talos-dashboard，地址：http://talos-dashboard:8080/talos-dashboard/index.html 123cd /usr/share/tomcatwget https://gitee.com/lhldyf/talos-readme/raw/master/talos-dashboard.warservice tomcat start talos-storage部署前请确认hosts已更新 1、下载talos-storage.zip2、解压至/usr/share/talos-storage3、启动talos-storage 12345cd /tmpwget https://gitee.com/lhldyf/talos-readme/raw/master/talos-storage.zipunzip /tmp/talos-storage.zip -d /usr/sharecd /usr/share/talos-storagesh bin/start.sh;tailf logs/stdout.log","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Kafka部署文档","slug":"Kafka部署文档","date":"2017-12-15T13:01:57.000Z","updated":"2017-12-22T09:57:24.639Z","comments":true,"path":"2017/12/15/Kafka部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Kafka部署文档/","excerpt":"机器列表 节点 建议host Node1 kafka1 zk1 Node2 kafka2 zk2 Node3 kafka3 zk3","text":"机器列表 节点 建议host Node1 kafka1 zk1 Node2 kafka2 zk2 Node3 kafka3 zk3 逻辑拓扑 部署步骤组件下载Download KafkaDownload Zookeeper 下载链接若失效，请参考官网最新链接 KafkaZookeeper Zookeeper安装 将zookeeper解压缩到/opt/zookeeper目录下 cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg 修改配置文件: vim /opt/zookeeper/conf/zoo.cfg 文件末尾加上 1234autopurge.purgeInterval=1server.1 = kafka1:2888:3888server.2 = kafka2:2888:3888server.3 = kafka3:2888:3888 /opt/zookeeper/bin/zkServer.sh start 启动 zk Kafka安装1、 将kafka解压缩到/opt/kafka目录下2、 修改/opt/kafka/config/consumer.properties文件，将zookeeper.connect=127.0.0.1:2181改成zookeeper.connect=zk1:2181,zk2:2181,zk3:21813、修改/opt/kafka/config/producer.properties文件，将bootstrap.servers=localhost:9092改成bootstrap.servers=kafka1:9092,kafka2:9092,kafka3:90924、修改/opt/kafka/config/server.properties文件，修改以下key： 123broker.id=2 （2表示node2，node1就是1，node3就是3）listeners=PLAINTEXT://127.0.0.1:9092 （本机ip）zookeeper.connect=zk1:2181,zk2:2181,zk3:2181 5、在/tmp/zookeeper目录下，新建一个myid文件，内容是2（node2就写2， node3就写3，同broker.id）6、进入/opt/kafka/bin/目录执行 ./kafka-server-start.sh ../config/server.properties &amp; 启动kafka","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Elasticsearch部署文档","slug":"Elasticsearch部署文档","date":"2017-12-15T11:57:07.000Z","updated":"2017-12-22T09:57:29.471Z","comments":true,"path":"2017/12/15/Elasticsearch部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Elasticsearch部署文档/","excerpt":"机器列表 节点 建议host Node1 es1 Node2 es2 Node3 es3","text":"机器列表 节点 建议host Node1 es1 Node2 es2 Node3 es3 环境准备1、JDK1.7+ 节点部署官网有quick-start 注意：Elasticsearch 限制使用非root用户来进行以下操作，如创建用户es 1、下载Elasticsearch2.4.0的zip包2、解压elasticsearch至/usr/share路径3、修改配置文件config/elasticsearch.yml 12345678910111213141516171819202122# es 集群名称，同一个集群名称需一致cluster.name: es-talos# es节点名称，每个节点设置不同，三个节点1/2/3即可node.name: node-1# 节点rack，每个节点设置不同，三个节点1/2/3即可node.rack: r1path.logs: /usr/share/elasticsearch-2.4.0/logs# 节点host，本机host即可network.host: es1http.port: 9200 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; # 集群部署的另外两个节点discovery.zen.ping.unicast.hosts: [&quot;es2&quot;,&quot;es3&quot;]discovery.zen.minimum_master_nodes: 2# 默认index刷新间隔 index.refresh_interval: 120s# 默认数据副本数index.number_of_replicas: 0# 设置脚本可执行script.inline: true script.indexed: true 4、修改elasticsearch jvm内存大小,建议值为本机物理内存/2修改文件install_path/bin/elasticsearch.in.sh文件中第16行及19行,设置ES_MIN_MEM=物理内存/2(16行)、ES_MAX_MEM=物理内存/2(19)行 5、解压后，使用es用户进行到bin目录下进行启动 1./elasticsearch -d 6、浏览器访问 es1:9200，看到如下响应则启动成功 123456789101112&#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;es-talos&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.4.0&quot;, &quot;build_hash&quot; : &quot;ce9f0c7394dee074091dd1bc4e9469251181fc55&quot;, &quot;build_timestamp&quot; : &quot;2016-08-29T09:14:17Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.2&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 以上1-6步骤在三个节点上操作完成，并都能看到启动成功的响应，则部署成功。 ES监控插件部署1、 如果在有网络的情况下可以直接执行/usr/share/elasticsearch2.4.0/bin/plugin install mobz/elasticsearch-head2、 如果服务器没有连网下载elasticsearch-head3、 可以通过web服务器打开，如将elasticsearch-head放到tomcat的里面，通过tomcat访问http://es1:8080/elasticsearch-head-master/index.html 部署成功如图：","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Talos接入使用说明","slug":"Talos接入使用说明","date":"2017-12-15T11:14:07.000Z","updated":"2017-12-22T10:03:55.924Z","comments":true,"path":"2017/12/15/Talos接入使用说明/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Talos接入使用说明/","excerpt":"运行环境开发环境开发环境需要： JDK1.7+ Maven3.1+","text":"运行环境开发环境开发环境需要： JDK1.7+ Maven3.1+ 依赖引入12345&lt;dependency&gt; &lt;groupId&gt;com.kxjf.talos&lt;/groupId&gt; &lt;artifactId&gt;talos-interceptor&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 使用说明这里对一些配置进行解释说明，范例代码移步talos-sample 配置说明必选配置Talos实例化Spring配置Talos实例，配置说明：1、 serviceName：用于区分集群应用，需唯一，建议取机器host2、 collector ：数据收集的实现方法，默认使用日志收集方式，需额外配置logback，系统目前提供这一种收集方式，可自行实现 参考配置： 12345&lt;bean id=&quot;talos&quot; class=&quot;com.kxd.talos.trace.core.Talos&quot;&gt; &lt;constructor-arg type=&quot;String&quot; value=&quot;talos-sample&quot; /&gt; &lt;constructor-arg type=&quot;float&quot; value=&quot;1.0f&quot; /&gt; &lt;constructor-arg ref=&quot;loggingSpanCollector&quot; /&gt;&lt;/bean&gt; logback配置配置logback.xml，需增加trace collector的日志输出配置，有几个自定义的环境配置，说明如下：1、 KAFKA_TOPIC_NAME: kafka推送的topic名称，用于接收日志数据2、 KAFKA_BOOTSTRAP_SERVERS ： kafka集群节点配置，” ip1:port1,ip2:port2…” 的方式配置即可。参考如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;appender name=&quot;talosTraceCollectorFileAppender&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--日志文件输出的文件名 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/$&#123;TALOS_TRACE_LOG_FILE&#125; &lt;/fileNamePattern&gt; &lt;!--日志文件保留天数 --&gt; &lt;MaxHistory&gt;$&#123;LOG_SAVE_DAYS&#125;&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;%msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;appender name=&quot;talosKafkaAppender&quot; class=&quot;com.github.danielwegener.logback.kafka.KafkaAppender&quot;&gt; &lt;encoderclass=&quot;com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt; %msg&lt;/pattern&gt; &lt;/layout&gt; &lt;/encoder&gt; &lt;topic&gt;$&#123;KAFKA_TOPIC_NAME&#125;&lt;/topic&gt; &lt;keyingStrategyclass=&quot;com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy&quot; /&gt; &lt;deliveryStrategyclass=&quot;com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy&quot; /&gt;&lt;producerConfig&gt;bootstrap.servers=$&#123;KAFKA_BOOTSTRAP_SERVERS&#125; &lt;/producerConfig&gt; &lt;!-- this is the fallback appender if kafka is not available. --&gt; &lt;appender-ref ref=&quot;talosTraceCollectorAppender&quot; /&gt;&lt;/appender&gt;&lt;appender name=&quot;asyncTalosKafkaAppender&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;appender-ref ref=&quot;talosKafkaAppender&quot; /&gt;&lt;/appender&gt;&lt;logger name=&quot;com.kxd.talos.trace.core.collector&quot; level=&quot;ALL&quot; additivity=&quot;true&quot;&gt; &lt;appender-ref ref=&quot;asyncTalosKafkaAppender&quot; /&gt; &lt;appender-ref ref=&quot;talosTraceCollectorFileAppender&quot; /&gt;&lt;/logger&gt; 配置logback.properties，参考如下： 123TALOS_TRACE_LOG_FILE=talos-trace_%d&#123;yyyy-MM-dd&#125;.logKAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092,kafka3:9092KAFKA_TOPIC_NAME=talos-open-source Web应用配置TalosServletFilterSpring配置TalosServletFilter实例，初始化配置filter中的Talos实例，参考如下： 123456&lt;bean id=&quot;httpServerServletFilter&quot; class=&quot;com.kxd.talos.trace.interceptor.server.http.TalosServletFilter&quot;&gt; &lt;property name=&quot;talos&quot; ref=&quot;talos&quot; /&gt; &lt;!-- 配置需要过滤的url,可使用*进行匹配,如有多个,用英文逗号(,)分割 --&gt; &lt;property name=&quot;patterns&quot; value=&quot;/**&quot; /&gt;&lt;/bean&gt; web.xml中增加配置，使用代理模式，参考如下： 12345678910111213141516&lt;filter&gt; &lt;filter-name&gt;TraceFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;targetBeanName&lt;/param-name&gt; &lt;param-value&gt;httpServerServletFilter&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;TraceFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 多线程配置使用约束：1、 多线程使用线程池方式(ThreadPoolExecutor)，不得使用new Thread()模式生成新线程2、 多线程方法必须实现Runable或Callable接口。Talos对spring 线程池ThreadPoolTaskExecutor 做了一层额外封装，收集多线程的相关数据，在使用多线程定义线程池时，额外实例化该类实例，执行线程池方法时，使用该实例，参考如下： 12345&lt;bean id=&quot;talosExecutorService&quot; class=&quot;com.kxd.talos.trace.core.concurrent.TalosSpringThreadPool&quot;&gt; &lt;constructor-arg ref=&quot;threadPoolExecutor&quot; /&gt; &lt;constructor-arg ref=&quot;talos&quot; /&gt;&lt;/bean&gt; 自定义采集配置自定义采集如果需要使用callback模式，需要配置callback的模板如下： TalosCallbackTemplateAOP的拦截有一定的限制性，对于一些无法进行AOP切面拦截的方法入口，如果有采集数据的必要性，Talos提供了callback模式的采集方式，需要新增的配置如下: 123&lt;bean id=&quot;talosCallbackTemplate&quot; class=&quot;com.kxd.talos.core.trace.TalosCallbackTemplate&quot;&gt; &lt;property name=&quot;talos&quot; ref=&quot;talos&quot;/&gt;&lt;/bean&gt; 数据采集说明自定义采集Talos提供两种自定义的数据采集方式,以下两种方式二选一即可 example: 123private void step3() &#123; aopServiceB.step4(); &#125; 这是现有的一个方法，无法通过AOP拦截，但又有数据采集的必要性，Talos系统提供两种实现方案，以下逐一说明： 方案一注入talos，通过start方法和finish方法完成数据采集，注意需要将方法用try..catch捕获异常，并在finally语句中做finish操作。 12345678910111213141516171819@Autowiredprivate Talos talos;private void step3() &#123; Span startSpan = talos.start(&quot;AopServiceA.step3&quot;); try &#123; aopServiceB.step4(); &#125; catch (AppException ae) &#123; startSpan.setExType(&quot;A&quot;); startSpan.setErrorCode(ae.getErrorCode()); throw ae; &#125; catch (Throwable t) &#123; startSpan.setExType(&quot;T&quot;); startSpan.setErrorCode(ErrorCode.ERROR_SERVICE_INTERCEPTOR_INVOKE); throw t; &#125; finally &#123; talos.finish(startSpan); &#125;&#125; 方案二注入TalosCallbackTemplate实例，将原有方法放在TalosCallback的execute方法即可。 123456789101112@Autowiredprivate TalosCallbackTemplate template;private void step3() &#123; template.execute(null, new TalosCallback()&#123; @Override public Object execute(Object request) &#123; aopServiceB.step4(); return null; &#125; &#125; );&#125; 业务数据采集注:为保证可在海量数据中对指定业务调用链进行搜索,建议每个业务均应当进行业务数据的采集,且该业务数据应当可唯一标识某次业务调用 为了更加易于检索出请求链路，业务人员必须在一个调用链中硬编码的方式写入一些业务数据。API为Talos.collect(String key, String value), 相关原则如下： 1、key 为英文字母组成，驼峰命名，需能根据该值知晓其代表的含义，比如userName, userId等。 2、value 长度不超过100，参数值确保可以方便的搜索出唯一一条调用链，或通过多个参数值确认一条调用链。参考使用如下： 1234public void withParam(ParamDto paramDto) &#123; Talos.collect(&quot;userName&quot;, paramDto.getUserName()); aopServiceB.step1();&#125; 多线程数据采集通过Spring注入TalosSpringThreadPool的实例，使用方法参考ThreadPoolTaskExecutor，参考如下： 1234567891011121314151617@Autowiredprivate TalosSpringThreadPool talosExecutorService;public void call2thread() &#123; talosExecutorService.submit(callableService); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; talosExecutorService.submit(callableService2); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"单元测试中mock框架的简单使用","slug":"单元测试中mock框架的简单使用","date":"2016-07-31T08:24:05.000Z","updated":"2018-01-16T09:18:11.693Z","comments":true,"path":"2016/07/31/单元测试中mock框架的简单使用/","link":"","permalink":"http://kplxq.github.io/2016/07/31/单元测试中mock框架的简单使用/","excerpt":"为什么要单元测试： 帮助理解需求：开发人员在编写测试代码的时候，可以更加清楚的了解代码的结构和业务逻辑。 尽早的发现bug：在&lt;快速软件开发&gt;这本书中指出，根据大量的研究数据证明：最后才修改一个bug的代价是在bug产生时修改它的代价大10倍。 提高局部代码的质量：保证局部代码质量，我们才能保证各个依赖你的其他模块的代码质量。 成本：这里说的测试成本是相对而言的，比如:对于集成测试的复杂环境部署，单元测试显得相对简单点。笔者简单了解了下笔者公司的开发写个单元测试平均在0.5H左右。 单元测试可以被复用：一劳永逸。一些固化的功能模块，只要我们写好单元测试后，以后基本不需要调整，为实现单元测试自动化打好了基础。","text":"为什么要单元测试： 帮助理解需求：开发人员在编写测试代码的时候，可以更加清楚的了解代码的结构和业务逻辑。 尽早的发现bug：在&lt;快速软件开发&gt;这本书中指出，根据大量的研究数据证明：最后才修改一个bug的代价是在bug产生时修改它的代价大10倍。 提高局部代码的质量：保证局部代码质量，我们才能保证各个依赖你的其他模块的代码质量。 成本：这里说的测试成本是相对而言的，比如:对于集成测试的复杂环境部署，单元测试显得相对简单点。笔者简单了解了下笔者公司的开发写个单元测试平均在0.5H左右。 单元测试可以被复用：一劳永逸。一些固化的功能模块，只要我们写好单元测试后，以后基本不需要调整，为实现单元测试自动化打好了基础。 当前单元测试遇到的问题：本地测试代价大：笔者所在公司有将近10个系统，有时候开发一个简单的功能，如果不发布到集成环境测试，在本地做单元测试至少需要启动2-3个系统才可以跑起来，经常IDE卡死。而发布到集成环境测试则耗时较长且调式麻烦。 复杂性：开发需要关心各种环境配置项的值，才可以正确的启动系统做单元测试，如：证书、密钥、验签等安全配置。特别是像笔者所在的这种金融领域，各种安全配置、银行调用URL配置。 不可控性：跨公司、跨部门、跨系统的接口调用，导致单元测试的效率和结果不可控。 异常分支测试：笔者做的金融系统，有很多和银行交互的接口，有的时候需要连接一下银行的测试环境测试下“难于上青天啊”(小银行会简单的配合你下，大银行根本不鸟你，给你一个地址你自己玩去吧)，更别说给你返回个异常数据了，连正常的数据都返回不了。另外比如：并发、系统压力测试(有的时候会选择硬编码将调用外部系统的地方写死，压力测试后再改回来上线，但是容易漏改、耗费人力、不能复用)，还有当前很流行的各种分布式、大数据的单元测试都比较困难。 常见的解决方案下面笔者简单分析下上述问题常见的解决方案(可能有更好的方案，这里笔者还没有想到,可以一起交流学习)： 问题1-solve. 部署一套稳定的环境：专门给开发人员单元测试连接调用，但是也存在一些问题，比如我们经常发现使用dubbo这样的RPC调用框架，会出现消费者和服务者混乱，因为共用一套环境大家都把自己的服务注册上去了。数据库数据会被别的开发修改，调式半天发现数据被别的开发修改了，这种情况痛苦的一比。 最理想的是一人一套环境，只有财大气粗的公司如此了。 问题2-solve. 统一开发目录和配置项：对于安全配置的证书这些问题比较好解决，所有开发共用一套单元测试环境变量配置，证书路径和url都统一。不同操作系统不同模板 问题3-solve. 万年难：问题三这个就比较难搞定了，例如你正在测试自己的case，突然你调用的B部门的服务出问题了，你会经常听到类似：我擦，服务被关闭了？他们在发布新版本？返回的数据不对啊、怎么用户不存在？我靠，他们又刷库了？。一等就是千万年，无法忍受。 当然笔者也曾经试着将这些接口调用全部写死了。直接new一个结果返回，然而细 心的人提交代码的时候可能会检查下，不细心的则深挖坑啊。。。。。。 问题4-solve. 写死返回结果：在需要异常场景的时候，注释掉调用代码，写死返回结果。基本和3类似。 后来基于3和4的解决思路，慢慢的就演变出了一种专门解决这些场景的框架：Mock框架。这也符合笔者一直崇尚的理念：**业务驱动开发，有需求就会诞生解决方案**。 Mock框架初接触笔者这里简单的说下自己的mock实现，如果有不足的地方还希望各路大神多多指教，相互学习成长。 选择TestNG: 首先做单元测试当然少不了junit或者testng了(也有NB的公司有自己的测试框架，这些公司呢想必也都是业务驱动逼迫自己去搞的)，笔者这里就不阐述着两个测试框架的区别了，网上各种帖子，总之适合自己、用的熟练、懂得原理就可以。那笔者这里选择的是testng。 选择Jmockit作为mock框架：另外一个就是mock框架的选型。当前的江湖中，mock框架已经有很多门派了，但是万变不离其宗，他们要么是JDK的动态代理、要不就是CGLIB的动态代理生成新的类。比如：easymock 、mockito、jmock等已经风生水起了，但是笔者认为这样的实现原理决定了它的局限性，比如：final方法、构造方法、不能被覆写的方法这些就不能被mock了。 思路到这里暂停一些，我们来回忆下最初的我们： 记得很多年前，我们在刚学java的时候，大神们就教导我们学习java，首先我们得知道一个java文件是怎么最终被机器执行的。 我们写了一个Hello.java 然后通过cmd命令javac Hello.java经过javac的编译器后完成了对代码的词法分析、语法分析、抽象语法树，然后得到一个Hello.class,这部分是在JVM外面的完成的。 然后由JVM类加载到内存中(这里笔者就不叙述加载的过程了，网上可以搜到很多相关文章，再说笔者自己了解的也是皮毛)。到JVM以后，然后JVM翻译成机器码执行。 有了这样的背景知识，再让我们思考如何mock一个类，我们自然的会想到的去修改这个类中在JVM中的字节码，这样就没有什么不可以mock的了。我们知道从JDK1.5开始就提供了java.lang.instrument包，其中提供了修改JVM中已加载类的重定义入口即java.lang.instrument.Instrumentation#redefineClasses(ClassDefinition...)方法。 那当前江湖中有没有这样的一个框架可以和我们的思路很符合呢？笔者google到了这样的一种框架，那就是JMockit(笔者一直认为框架只要适合自己能够满足业务场景就好，无需过多的去追求时髦)。 Jmockit简单介绍： JMockit：是googlecode上的一个项目衍生而来，现在已经有了自己的独立门户网站，官网介绍其是基于asm库来修改java的字节码从而达到篡改类的行为的mock工具。通过JDK提供的类重定义方法：java.lang.instrument.Instrumentation#redefineClasses(ClassDefinition…)作为修改JVM中类的定义的入口。 这样mock框架就定了。是时候我们设计下我们蓝图了。 融合TestNG和JMockit 框架设计： AbstractMockBase：mock类的基类，为以后扩展预留。 TestAMock: 具体的Mock实现类。 mockContext.xml：所有的mock类集中于xml中进行管理，然后写了一个JMockitBeanFactory加载这些类。方便以后统计、修改。 JMockitBase：所有需要用到mock的单元测试类继承此类，提供getMockBean方法。 AbstractDataProvider：提供从xml读取单元测试源数据入口。 TestNGIInvokedMethodListener：testng中的IInvokedMethodListener监听接口实现，完成MockInfo注解的实现。 注：JMockit是通过类TestNGRunnerDecorator实现Testng的两个接口：IInvokedMethodListener，IExecutionListener来实现和TestNG交互的.。 另外我们mock spring容器中bean的时候，一定要拿到被代理前的原始类。方法如下： 编码实战版本 Testng：6.8 Jmockit：1.21 其他的Spring依赖各位随意吧. 场景一: mock原有的接口返回 笔者这里以金融系统中查询工作日这样的接口举例，通常这种查询我们都会调用一个单独的统一辅助系统去查询某天是否是工作日，然后依次来判断下一步的逻辑。但是笔者希望他永远返回是工作日，且不用配置远程调用的任何信息。(最直接的就是在调用出修改代码，写死返回值，这样虽然可以解决问题但是就像前面笔者说的，复用性不强且容易出问题) 下面笔者列举出Mock主要的代码实现,完整代码笔者会稍后上传到github上。 a. 工作日查询接口 b. 工作日查询接口实现编写WorkDayAssistant的mock类:空父类，以后扩展用 Mock类(类的部分mock)(Jmock分类局部mock和全部mock)基金购买接口基金购买接口实现 c. 自定义MockInfo注解-用于定义当前test method 运行时需要哪些bean被mock 运行测试 运行结果： 场景二: 从xml获取数据源 对于一些模块和功能已经固化的代码，我们希望用固定的数据在每个迭代版本中都可以得到固定的结果，笔者这里拿金融系统中常见的绑卡场景为例。 定义xml格式 DataProvider编写 数据获取使用(这里取数据比较恶心，要从map中get，笔者计划有时间改成JavaBean字段映射) 运行结果： 然已经取到数据了，那后面的测试和结果校验随意吧。 总结：当前笔者只是简单介绍了框架的简单使用和集成，后续笔者将抽时间将Jmockit的原理、详细使用方法、当期框架设计优化改进的地方再发表出来和大家一起学习交流。 作者：猎狐，就职于开鑫金服，主要负责Java Web方向的开发工作。","categories":[],"tags":[{"name":"mock框架","slug":"mock框架","permalink":"http://kplxq.github.io/tags/mock框架/"}],"keywords":[]},{"title":"React一小时入门","slug":"React一小时入门","date":"2016-07-27T08:23:36.000Z","updated":"2018-01-16T09:18:28.180Z","comments":true,"path":"2016/07/27/React一小时入门/","link":"","permalink":"http://kplxq.github.io/2016/07/27/React一小时入门/","excerpt":"React是Facebook开发的js库，不仅影响了其他前端库的开发思路，而且还引申出React Native等技术，在开源世界引起了极大的反响。 Facebook为什么要花费大量的精力开发React，为了解决什么问题，以及如何解决问题，我们将就这些问题做一些简单的讨论和学习。","text":"React是Facebook开发的js库，不仅影响了其他前端库的开发思路，而且还引申出React Native等技术，在开源世界引起了极大的反响。 Facebook为什么要花费大量的精力开发React，为了解决什么问题，以及如何解决问题，我们将就这些问题做一些简单的讨论和学习。 React背景Facebook在开发广告系统时发现，因为他们非常庞大的代码库，导致前端的MVC架构非常复杂难以维护。每当开发新需求时，系统复杂度成倍增长，代码非常脆弱且执行结果不可预测。所以Facebook认为MVC架构不适合开发大规模的前端应用，其中很重要的原因是应用中的模型（M）和视图（V）之间的双向数据绑定导致前端代码复杂度迅速提高，难以理解和调试，极大地影响Facebook的开发效率。 Facebook给出的解决方案就是React。React在Facebook内部已经试用了多年，效果很好。React另辟蹊径解决前端代码复杂度高的问题，JSX语法甚至被初学者认为不伦不类。但是我在尝试了React之后，我无法自拔地喜欢上了这种单向数据驱动的开发思路。 那么React是解决什么问题的呢，Facebook官网上介绍说： We built React to solve one problem: building large applications with data that changes over time. 即React是用来构建那些数据会随时改变的大型应用。为了构建大型应用，React有两个主要的特点： 简洁代码里非常简单的描述在每个时间点应用应该呈现的样子。当应用数据改变时，React会自动管理UI界面。 声明式当数据发生改变时，React表现的是刷新DOM树。但事实上React仅仅更新发生了变化的那一部分。我们要做的就是构建组件（Component），封装组件。React自动管理组件的生命周期。 React特性React有三大特性：组件化、虚拟DOM和单向数据流。这三大特性是React运行的基础，并且由虚拟DOM衍生出React Native项目。 组件化React允许将代码封装成组件（Component），然后像插入普通HTML标签一样，在页面中插入这个组件(源码参见：https://github.com/xeostream/react-demo/blob/master/helloworld.html)。 上述代码中，变量HelloMessage就是一个组件类。所有的组件类必须有render方法，用于输出组件内容。 组件的用法与原生的HTML标签完全一致，可以任意加入属性。比如，就是在HelloMessage组件中加入message属性，值为“yo，what’up,man?”。组件内部可以通过this.props对象获取组件的属性，this.props.message就是取message属性值。上面代码的运行结果如下。 组件化的最显著特征就是万物皆由组件构成，那么多个组件之间相互通信就是很大的问题。一般解决方式有三种： 使用props，构建通信链 在组件初始化时，保存组件的句柄。在其他组件中使用句柄达到直接访问组件的目的，完成通信 使用PubSub模式 首先第一种方法容易理解，但是在组件嵌套较深的情况下，为达到通信的目的，组件之间相互调用而且组件需要冗余许多不需要的props，不太适合；第二种方法避免了第一种方法的问题，但是需要维护很多变量，也不是非常好的方案；对于第三种方法，PubSub模式有助于组件解耦和代码组织，而且PubSub有很多开源实现。建议组件间通信使用PubSub模式。 虚拟DOM当组件状态改变的时候，React会自动调用组件的render方法重新渲染整个组件的UI。 但是如果这样大面积的操作DOM，性能会是一个很大的问题，所以React实现了虚拟DOM。 虚拟DOM是一个纯粹的JS数据结构，存到内存中，性能很快。React将组件的DOM结构映射到虚拟DOM上，在虚拟DOM上实现了一个高效的diff算法。所以每次当组件的数据更新时，React会通过diff算法找到需要更新的DOM节点，再把修改更新到浏览器实际的DOM节点上。 单向数据流 单向数据流是React推崇的一种应用架构的方式。在React的组件中，我们监听状态的变化，并在组件的声明周期函数里对组件状态做一个的响应和操作，即页面的变化只与状态数据的变更有关。这里展示一种官方的单向数据流实现： （注：Flux由单向数据流扩展而来，React与Flux相互独立，React仅实现Flux架构中的View部分。当然也可以使用其他js库实现这个View。） 这里我们将React组件理解为一个状态机，状态机内部的状态发生了改变，则对外的输出也会发生改变，两者之间的关系是一一对应的，即如果组件的状态数据是确定的话，则组件的输出也是确定的。这点对于前端的测试和DEBUG是非常大的帮助，对减少前端BUG是很有好处的。 我开始不太理解单向数据流的概念，因为搞不清楚单向数据流和MVC的关系。其实单向数据流并不是和MVC在同一层次对系统的抽象，单向数据流表达的是MVC中View和Model之间数据的传递方式。所以这个问题更精确的表达应该是单向数据流和双向数据流之间的对比。 双向数据流常见于Angular1.x等库中，指Model和View可以相互传递数据，且多个Model和View之间传递没有限制，其中传递是代码不需要显式设置监听事件以同步数据，而是Model和View相互绑定。 所以双向数据流的优势是容易理解，在简单系统中开发非常方便；但是缺点是在复杂工程中，多个Model和View之间绑定，保持这种绑定关系极耗性能，经常会导致View无响应，性能急剧下降，而且因为存在多层绑定关系，导致View的Debug几乎不可能。基于以上原因，很多前端框架如angular2.0已经开始将单向数据流作为默认的绑定方式。 React原理上面一直在说React是要解决什么问题的，现在说下React是怎么解决这些问题的？ 传统的web应用，操作DOM一般是直接更新操作或者是大面积页面刷新，这种操作是比较昂贵的。React为了尽量减少对DOM的操作，提供了一种与众不同的方式来更新DOM。就是DOM层之前增加一个轻量级的虚拟DOM，虚拟DOM是React抽象出来的描述真实DOM结构的对象，由虚拟DOM管理真实DOM的更新。 虚拟DOM为保证高效的更新真实DOM，在更新之前增加diff算法计算出真实DOM的最小变更。 在真实DOM树上的节点被称为元素，在虚拟DOM里被称为组件。组件是非常重要的，虚拟DOM是由组件组成。 component 的使用在 React 里极为重要, 因为 components 的存在让计算 DOM diff 更高效。 state、props和render在组件中是非常重要的属性。state、props属性包含定义组件需要的数据。state表示组件当前的状态，当state发生变化时，组件会调用render方法重新渲染。相对于state，props是组件初始化需要的数据，React规约props在组件的生命周期内无法更改也不应改变。 在组件的生命周期中，随着该组件的props和state发生改变，组件的DOM表现也会有相应的变化。一个组件即是一个状态机，对于特定地输入，组件总返回一致的输出。 组件的生命周期可以分为三大过程。分别为： mounted组件被渲染为真实的DOM元素插入浏览器的DOM结构的一个过程。 update已经处于mounted状态的组件被重新渲染的过程。 unmounted处于mounted状态的组件被从浏览器DOM结构中移除的过程。 组件的完整生命周期如下： 在组件的生命周期中有几个比较重要的方法： getDefaultProps此方法返回的对象可以用于设置默认的props值。 getInitialState此方法用来初始化组件实例的state，在这个方法里可以访问组件的props变量。 componentWillMount此方法在组件首次渲染之前调用，是在调用render方法之前最后一次修改组件的机会。 render此方法会创建一个虚拟DOM，用来表示组件的输出。在组件中，render方法是必须的方法。render方法本身需要满足几点： 只能通过this.props和this.state访问组件的数据 可以返回null，false或者任何React组件 返回结果只能有一个顶级组件，不能返回一组元素 componentDidMount此方法在render方法执行之后被调用，所以在方法中可以获取组件在真实DOM的节点。 shouldComponentUpdate此方法决定组件是否重新渲染，如果方法返回结果为false的话，则组件不会调用render方法重新渲染。 componentWillUpdate此方法和componentWillMount类似，渲染后的组件在接收到新的props或者state改变之后，组件会调用此方法。 componentDidUpdate组件因接收到新的props或者state改变导致的重新渲染之后，会调用此方法，所以可以在方法中访问或者修改真实DOM。 componentWillUnmount当组件从DOM中卸载后销毁，会调用此方法完成所有的清理和销毁工作。在conponentDidMount中添加的任务都需要在此方法中销毁，比如创建的定时器和事件监听器。 React示例计时器 github源码 执行结果（原本想做个GIF，然而并不会做。。。）： React体验 使用单向数据流可以很好的隔绝业务，大大降低了单元测试的难度。 尽量将React组件（Component）做到小，做到细，也就是尽量拆分React组件。 基于数据驱动的方式开发，虽然开始的时候不容易理解，但确实可以减少前端的BUG。 React更适合数据驱动的项目，不太适应交互比较多的项目。 作者：王建双，就职于开鑫贷，主要负责Java Web方向的开发工作，也会根据兴趣涉猎前端相关的开发技术。目前在学习React和React Native、Spring高级特性。本人水平有限，欢迎各路大神就本文观点和出现的错误进一步的讨论。","categories":[],"tags":[{"name":"React","slug":"React","permalink":"http://kplxq.github.io/tags/React/"}],"keywords":[]}]}