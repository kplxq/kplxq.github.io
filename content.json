{"meta":{"title":"开普勒鑫球","subtitle":null,"description":"dapper talos","author":"开普勒鑫球","url":"http://kplxq.github.io"},"pages":[{"title":"关于我们","date":"2018-01-06T09:48:39.942Z","updated":"2018-01-06T09:48:39.942Z","comments":true,"path":"about/index.html","permalink":"http://kplxq.github.io/about/index.html","excerpt":"","text":"开普勒鑫球是一个开放式的技术团体，是新金融科技的先行者。我们将探索金融科技发展，用新科技打造新金融，通过技术孵化、知识分享、项目开源，与业界同行共进。 开源项目 Talos github gitee QQ交流群：637375352 微信群：请联系管理员加入 微信公众号： 官方社区：www.kplxq.com"},{"title":"Categories","date":"2017-12-21T14:20:50.796Z","updated":"2017-12-21T14:20:50.796Z","comments":true,"path":"categories/index.html","permalink":"http://kplxq.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-12-21T14:20:50.796Z","updated":"2017-12-21T14:20:50.796Z","comments":true,"path":"tags/index.html","permalink":"http://kplxq.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"开普勒鑫球全链路监控系统Talos正式开源","slug":"开普勒鑫球全链路监控系统Talos正式开源","date":"2017-12-15T15:17:13.000Z","updated":"2018-01-06T11:36:45.688Z","comments":true,"path":"2017/12/15/开普勒鑫球全链路监控系统Talos正式开源/","link":"","permalink":"http://kplxq.github.io/2017/12/15/开普勒鑫球全链路监控系统Talos正式开源/","excerpt":"2017年12月24日，开普勒鑫球的开源社区正式对外发布了其首个开源项目- Talos。","text":"2017年12月24日，开普勒鑫球的开源社区正式对外发布了其首个开源项目- Talos。 Talos是一个大数据全链路监控系统，由开鑫金服科技团队自主研发，供业界下载使用。开鑫金服科技团队期望通过这种开源的方式促进行业交流、发展，共同进步。 Talos以Google Dapper论文为理论基础，参照Twitter Brave的实现方案，面向当今互联网复杂的环境，基于客户端探针上报应用调用链相关日志，通过ElasticSearch引擎和HBase大数据存储技术，对海量请求进行实时链式跟踪、预警，能快速定位问题根源，有效保障了系统的稳定运行，提升了客户体验。 开鑫金服科技团队通过5年的磨砺，自主研发了多项先进的框架和平台。2017年12月24日，开鑫金服公司成立5周年，为迎接这有意义的一天，团队决定将Talos项目贡献给开普勒鑫球的开源社区；同时也期望更多的技术爱好者加入到开源社区中来，共同分享、交流。开普勒鑫球开源社区后续还会开源更多优质领先的项目，敬请期待！ 开源地址（或点击开普勒鑫球公众号菜单【开源项目】直接访问）：","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"如何设计一个大数据全链路监控系统","slug":"【纯干货分享】如何设计一个大数据全链路监控系统","date":"2017-12-15T15:07:13.000Z","updated":"2018-01-06T11:37:31.032Z","comments":true,"path":"2017/12/15/【纯干货分享】如何设计一个大数据全链路监控系统/","link":"","permalink":"http://kplxq.github.io/2017/12/15/【纯干货分享】如何设计一个大数据全链路监控系统/","excerpt":"纯干货分享！ 大数据全链路监控系统架构设计内部PPT来啦，赶紧保存。 后续开普勒鑫球还会陆续发布一系列文章逐一展开详细讲解，手把手教你，干货满满，敬请关注吧！","text":"纯干货分享！ 大数据全链路监控系统架构设计内部PPT来啦，赶紧保存。 后续开普勒鑫球还会陆续发布一系列文章逐一展开详细讲解，手把手教你，干货满满，敬请关注吧！","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"部署文档","slug":"部署文档","date":"2017-12-15T14:59:56.000Z","updated":"2017-12-22T10:00:06.488Z","comments":true,"path":"2017/12/15/部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/部署文档/","excerpt":"整体部署架构","text":"整体部署架构 部署节点数及基准配置 组件名称 组件类型 建议节点数 基准配置 搜索引擎(elastic search) 中间件 Elastic Search(3) cpu:2C memory:8G 分布式列存储数据库(Hbase) 中间件 CDH Manager(1) cpu:2C memory:4G disk:50G 分布式列存储数据库(Hbase) 中间件 Hbase MasterServer(1) cpu:2C memory:4G disk:50G 分布式列存储数据库(Hbase) 中间件 Hbase RegionServer(2) cpu:2C memory:4G disk:150G(留存30天数据) 分布式队列服务器(Kafka) 中间件 Kafka Server(3) cpu:2C memory:4G disk:20G 分布式配置管理服务器(zookeeper) 中间件 Zookeeper Server(3) cpu:2C memory:4G talos-storage 自有组件 2 cpu:2C memory:4G disk:20G talos-dashboard 自有组件 1 cpu:2C memory:4G disk:20G 部署步骤hosts配置在部署前请维护整个集群环境的hosts，并推送到每个部署节点 12345678910111213141516171819202122#es 集群192.168.99.101 es1192.168.99.102 es2192.168.99.103 es3# kafka集群192.168.99.104 kafka1 zk1192.168.99.105 kafka2 zk2192.168.99.106 kafka3 zk3# hbase集群192.168.99.107 hbase1192.168.99.108 hbase2192.168.99.109 hbase3192.168.99.110 cdhmaster# talos-dashboard192.168.99.111 talos-dashboard# talos-storage192.168.99.112 talos-storage1192.168.99.113 talos-storage2 中间件安装中间件版本信息如下: 中间件名称 版本 备注 搜索引擎 Elastic Search-2.4.0 3个节点 分布式列存储数据库 Hbase-1.2.0(CDH-5.8.0) 4个节点 CDH Manager(1) Hbase MasterServer() Hbase RegionServer(2) 分布式队列服务器 Kafka-2.11-0.10.0.1 3个节点 分布式文件系统 Hdfs-2.6.0(CDH-5.8.0) 内嵌至Hbase部署中 分布式配置管理服务器 Zookeeper-3.4.5(CDH-5.8.0) - Kafka1、中间件安装另附文档Kafka部署文档2、创建Talos系统在kafka集群所用的topic 配置如下： topic名称：talos-open-sourcepartition数目：1024replication数据：1 (无需备份) 脚本如下： 1./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1024 --topic talos-open-source Elasticsearch1、中间件安装另附文档Elasticsearch部署文档2、创建Talos系统elasticsearch索引 配置如下：index： talosmapping: trace刷新时间：5s分片数：5备份：0 123456789101112131415curl -XPOST http://es1:9200/talos -d &apos;&#123; &quot;settings&quot; : &#123; &quot;number_of_replicas&quot;: &quot;0&quot;, &quot;number_of_shards&quot;: &quot;5&quot;, &quot;refresh_interval&quot;: &quot;5s&quot; &#125;, &quot;mappings&quot; : &#123; &quot;trace&quot; : &#123; &quot;properties&quot; : &#123; &quot;traceid&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot; &#125;, &quot;contents&quot; : &#123; &quot;type&quot; : &quot;string&quot;&#125; &#125; &#125; &#125;&#125;&apos; HBase1、中间件安装参考HBase部署文档2、创建Talos系统Hbase表 配置如下：表名：tracerowkey: id （talos系统中的traceId)列族：span （talos系统中的不同的spanId即为该列族下的不同列）数据失效时间：30天 脚本如下（在hbase shell中执行）： 1create &apos;trace&apos;, &#123;NAME=&gt;&apos;id&apos;, TTL=&gt;&apos;2592000&apos;&#125;,&#123;NAME=&gt;&apos;span&apos;, TTL=&gt;&apos;2592000&apos;&#125; 系统自有组件安装talos-dashboard部署前请确认hosts已更新 1、下载talos-dashboard.war2、将talos-dashboard包放到tomcat/webapps路径下3、启动tomcat4、浏览器打开talos-dashboard，地址：http://talos-dashboard:8080/talos-dashboard/index.html 123cd /usr/share/tomcatwget https://gitee.com/lhldyf/talos-readme/raw/master/talos-dashboard.warservice tomcat start talos-storage部署前请确认hosts已更新 1、下载talos-storage.zip2、解压至/usr/share/talos-storage3、启动talos-storage 12345cd /tmpwget https://gitee.com/lhldyf/talos-readme/raw/master/talos-storage.zipunzip /tmp/talos-storage.zip -d /usr/sharecd /usr/share/talos-storagesh bin/start.sh;tailf logs/stdout.log","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Kafka部署文档","slug":"Kafka部署文档","date":"2017-12-15T13:01:57.000Z","updated":"2017-12-22T09:57:24.639Z","comments":true,"path":"2017/12/15/Kafka部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Kafka部署文档/","excerpt":"机器列表 节点 建议host Node1 kafka1 zk1 Node2 kafka2 zk2 Node3 kafka3 zk3","text":"机器列表 节点 建议host Node1 kafka1 zk1 Node2 kafka2 zk2 Node3 kafka3 zk3 逻辑拓扑 部署步骤组件下载Download KafkaDownload Zookeeper 下载链接若失效，请参考官网最新链接 KafkaZookeeper Zookeeper安装 将zookeeper解压缩到/opt/zookeeper目录下 cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg 修改配置文件: vim /opt/zookeeper/conf/zoo.cfg 文件末尾加上 1234autopurge.purgeInterval=1server.1 = kafka1:2888:3888server.2 = kafka2:2888:3888server.3 = kafka3:2888:3888 /opt/zookeeper/bin/zkServer.sh start 启动 zk Kafka安装1、 将kafka解压缩到/opt/kafka目录下2、 修改/opt/kafka/config/consumer.properties文件，将zookeeper.connect=127.0.0.1:2181改成zookeeper.connect=zk1:2181,zk2:2181,zk3:21813、修改/opt/kafka/config/producer.properties文件，将bootstrap.servers=localhost:9092改成bootstrap.servers=kafka1:9092,kafka2:9092,kafka3:90924、修改/opt/kafka/config/server.properties文件，修改以下key： 123broker.id=2 （2表示node2，node1就是1，node3就是3）listeners=PLAINTEXT://127.0.0.1:9092 （本机ip）zookeeper.connect=zk1:2181,zk2:2181,zk3:2181 5、在/tmp/zookeeper目录下，新建一个myid文件，内容是2（node2就写2， node3就写3，同broker.id）6、进入/opt/kafka/bin/目录执行 ./kafka-server-start.sh ../config/server.properties &amp; 启动kafka","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Elasticsearch部署文档","slug":"Elasticsearch部署文档","date":"2017-12-15T11:57:07.000Z","updated":"2017-12-22T09:57:29.471Z","comments":true,"path":"2017/12/15/Elasticsearch部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Elasticsearch部署文档/","excerpt":"机器列表 节点 建议host Node1 es1 Node2 es2 Node3 es3","text":"机器列表 节点 建议host Node1 es1 Node2 es2 Node3 es3 环境准备1、JDK1.7+ 节点部署官网有quick-start 注意：Elasticsearch 限制使用非root用户来进行以下操作，如创建用户es 1、下载Elasticsearch2.4.0的zip包2、解压elasticsearch至/usr/share路径3、修改配置文件config/elasticsearch.yml 12345678910111213141516171819202122# es 集群名称，同一个集群名称需一致cluster.name: es-talos# es节点名称，每个节点设置不同，三个节点1/2/3即可node.name: node-1# 节点rack，每个节点设置不同，三个节点1/2/3即可node.rack: r1path.logs: /usr/share/elasticsearch-2.4.0/logs# 节点host，本机host即可network.host: es1http.port: 9200 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; # 集群部署的另外两个节点discovery.zen.ping.unicast.hosts: [&quot;es2&quot;,&quot;es3&quot;]discovery.zen.minimum_master_nodes: 2# 默认index刷新间隔 index.refresh_interval: 120s# 默认数据副本数index.number_of_replicas: 0# 设置脚本可执行script.inline: true script.indexed: true 4、修改elasticsearch jvm内存大小,建议值为本机物理内存/2修改文件install_path/bin/elasticsearch.in.sh文件中第16行及19行,设置ES_MIN_MEM=物理内存/2(16行)、ES_MAX_MEM=物理内存/2(19)行 5、解压后，使用es用户进行到bin目录下进行启动 1./elasticsearch -d 6、浏览器访问 es1:9200，看到如下响应则启动成功 123456789101112&#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;es-talos&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.4.0&quot;, &quot;build_hash&quot; : &quot;ce9f0c7394dee074091dd1bc4e9469251181fc55&quot;, &quot;build_timestamp&quot; : &quot;2016-08-29T09:14:17Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.2&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 以上1-6步骤在三个节点上操作完成，并都能看到启动成功的响应，则部署成功。 ES监控插件部署1、 如果在有网络的情况下可以直接执行/usr/share/elasticsearch2.4.0/bin/plugin install mobz/elasticsearch-head2、 如果服务器没有连网下载elasticsearch-head3、 可以通过web服务器打开，如将elasticsearch-head放到tomcat的里面，通过tomcat访问http://es1:8080/elasticsearch-head-master/index.html 部署成功如图：","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Talos接入使用说明","slug":"Talos接入使用说明","date":"2017-12-15T11:14:07.000Z","updated":"2017-12-22T10:03:55.924Z","comments":true,"path":"2017/12/15/Talos接入使用说明/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Talos接入使用说明/","excerpt":"运行环境开发环境开发环境需要： JDK1.7+ Maven3.1+","text":"运行环境开发环境开发环境需要： JDK1.7+ Maven3.1+ 依赖引入12345&lt;dependency&gt; &lt;groupId&gt;com.kxjf.talos&lt;/groupId&gt; &lt;artifactId&gt;talos-interceptor&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 使用说明这里对一些配置进行解释说明，范例代码移步talos-sample 配置说明必选配置Talos实例化Spring配置Talos实例，配置说明：1、 serviceName：用于区分集群应用，需唯一，建议取机器host2、 collector ：数据收集的实现方法，默认使用日志收集方式，需额外配置logback，系统目前提供这一种收集方式，可自行实现 参考配置： 12345&lt;bean id=&quot;talos&quot; class=&quot;com.kxd.talos.trace.core.Talos&quot;&gt; &lt;constructor-arg type=&quot;String&quot; value=&quot;talos-sample&quot; /&gt; &lt;constructor-arg type=&quot;float&quot; value=&quot;1.0f&quot; /&gt; &lt;constructor-arg ref=&quot;loggingSpanCollector&quot; /&gt;&lt;/bean&gt; logback配置配置logback.xml，需增加trace collector的日志输出配置，有几个自定义的环境配置，说明如下：1、 KAFKA_TOPIC_NAME: kafka推送的topic名称，用于接收日志数据2、 KAFKA_BOOTSTRAP_SERVERS ： kafka集群节点配置，” ip1:port1,ip2:port2…” 的方式配置即可。参考如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;appender name=&quot;talosTraceCollectorFileAppender&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--日志文件输出的文件名 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/$&#123;TALOS_TRACE_LOG_FILE&#125; &lt;/fileNamePattern&gt; &lt;!--日志文件保留天数 --&gt; &lt;MaxHistory&gt;$&#123;LOG_SAVE_DAYS&#125;&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;%msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;appender name=&quot;talosKafkaAppender&quot; class=&quot;com.github.danielwegener.logback.kafka.KafkaAppender&quot;&gt; &lt;encoderclass=&quot;com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt; %msg&lt;/pattern&gt; &lt;/layout&gt; &lt;/encoder&gt; &lt;topic&gt;$&#123;KAFKA_TOPIC_NAME&#125;&lt;/topic&gt; &lt;keyingStrategyclass=&quot;com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy&quot; /&gt; &lt;deliveryStrategyclass=&quot;com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy&quot; /&gt;&lt;producerConfig&gt;bootstrap.servers=$&#123;KAFKA_BOOTSTRAP_SERVERS&#125; &lt;/producerConfig&gt; &lt;!-- this is the fallback appender if kafka is not available. --&gt; &lt;appender-ref ref=&quot;talosTraceCollectorAppender&quot; /&gt;&lt;/appender&gt;&lt;appender name=&quot;asyncTalosKafkaAppender&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;appender-ref ref=&quot;talosKafkaAppender&quot; /&gt;&lt;/appender&gt;&lt;logger name=&quot;com.kxd.talos.trace.core.collector&quot; level=&quot;ALL&quot; additivity=&quot;true&quot;&gt; &lt;appender-ref ref=&quot;asyncTalosKafkaAppender&quot; /&gt; &lt;appender-ref ref=&quot;talosTraceCollectorFileAppender&quot; /&gt;&lt;/logger&gt; 配置logback.properties，参考如下： 123TALOS_TRACE_LOG_FILE=talos-trace_%d&#123;yyyy-MM-dd&#125;.logKAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092,kafka3:9092KAFKA_TOPIC_NAME=talos-open-source Web应用配置TalosServletFilterSpring配置TalosServletFilter实例，初始化配置filter中的Talos实例，参考如下： 123456&lt;bean id=&quot;httpServerServletFilter&quot; class=&quot;com.kxd.talos.trace.interceptor.server.http.TalosServletFilter&quot;&gt; &lt;property name=&quot;talos&quot; ref=&quot;talos&quot; /&gt; &lt;!-- 配置需要过滤的url,可使用*进行匹配,如有多个,用英文逗号(,)分割 --&gt; &lt;property name=&quot;patterns&quot; value=&quot;/**&quot; /&gt;&lt;/bean&gt; web.xml中增加配置，使用代理模式，参考如下： 12345678910111213141516&lt;filter&gt; &lt;filter-name&gt;TraceFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;targetBeanName&lt;/param-name&gt; &lt;param-value&gt;httpServerServletFilter&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;TraceFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 多线程配置使用约束：1、 多线程使用线程池方式(ThreadPoolExecutor)，不得使用new Thread()模式生成新线程2、 多线程方法必须实现Runable或Callable接口。Talos对spring 线程池ThreadPoolTaskExecutor 做了一层额外封装，收集多线程的相关数据，在使用多线程定义线程池时，额外实例化该类实例，执行线程池方法时，使用该实例，参考如下： 12345&lt;bean id=&quot;talosExecutorService&quot; class=&quot;com.kxd.talos.trace.core.concurrent.TalosSpringThreadPool&quot;&gt; &lt;constructor-arg ref=&quot;threadPoolExecutor&quot; /&gt; &lt;constructor-arg ref=&quot;talos&quot; /&gt;&lt;/bean&gt; 自定义采集配置自定义采集如果需要使用callback模式，需要配置callback的模板如下： TalosCallbackTemplateAOP的拦截有一定的限制性，对于一些无法进行AOP切面拦截的方法入口，如果有采集数据的必要性，Talos提供了callback模式的采集方式，需要新增的配置如下: 123&lt;bean id=&quot;talosCallbackTemplate&quot; class=&quot;com.kxd.talos.core.trace.TalosCallbackTemplate&quot;&gt; &lt;property name=&quot;talos&quot; ref=&quot;talos&quot;/&gt;&lt;/bean&gt; 数据采集说明自定义采集Talos提供两种自定义的数据采集方式,以下两种方式二选一即可 example: 123private void step3() &#123; aopServiceB.step4(); &#125; 这是现有的一个方法，无法通过AOP拦截，但又有数据采集的必要性，Talos系统提供两种实现方案，以下逐一说明： 方案一注入talos，通过start方法和finish方法完成数据采集，注意需要将方法用try..catch捕获异常，并在finally语句中做finish操作。 12345678910111213141516171819@Autowiredprivate Talos talos;private void step3() &#123; Span startSpan = talos.start(&quot;AopServiceA.step3&quot;); try &#123; aopServiceB.step4(); &#125; catch (AppException ae) &#123; startSpan.setExType(&quot;A&quot;); startSpan.setErrorCode(ae.getErrorCode()); throw ae; &#125; catch (Throwable t) &#123; startSpan.setExType(&quot;T&quot;); startSpan.setErrorCode(ErrorCode.ERROR_SERVICE_INTERCEPTOR_INVOKE); throw t; &#125; finally &#123; talos.finish(startSpan); &#125;&#125; 方案二注入TalosCallbackTemplate实例，将原有方法放在TalosCallback的execute方法即可。 123456789101112@Autowiredprivate TalosCallbackTemplate template;private void step3() &#123; template.execute(null, new TalosCallback()&#123; @Override public Object execute(Object request) &#123; aopServiceB.step4(); return null; &#125; &#125; );&#125; 业务数据采集注:为保证可在海量数据中对指定业务调用链进行搜索,建议每个业务均应当进行业务数据的采集,且该业务数据应当可唯一标识某次业务调用 为了更加易于检索出请求链路，业务人员必须在一个调用链中硬编码的方式写入一些业务数据。API为Talos.collect(String key, String value), 相关原则如下： 1、key 为英文字母组成，驼峰命名，需能根据该值知晓其代表的含义，比如userName, userId等。 2、value 长度不超过100，参数值确保可以方便的搜索出唯一一条调用链，或通过多个参数值确认一条调用链。参考使用如下： 1234public void withParam(ParamDto paramDto) &#123; Talos.collect(&quot;userName&quot;, paramDto.getUserName()); aopServiceB.step1();&#125; 多线程数据采集通过Spring注入TalosSpringThreadPool的实例，使用方法参考ThreadPoolTaskExecutor，参考如下： 1234567891011121314151617@Autowiredprivate TalosSpringThreadPool talosExecutorService;public void call2thread() &#123; talosExecutorService.submit(callableService); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; talosExecutorService.submit(callableService2); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]}]}