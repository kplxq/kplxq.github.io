{"meta":{"title":"开普勒鑫球","subtitle":null,"description":"dapper talos","author":"开普勒鑫球","url":"http://kplxq.github.io"},"pages":[{"title":"关于我们","date":"2018-01-06T09:48:39.942Z","updated":"2018-01-06T09:48:39.942Z","comments":true,"path":"about/index.html","permalink":"http://kplxq.github.io/about/index.html","excerpt":"","text":"开普勒鑫球是一个开放式的技术团体，是新金融科技的先行者。我们将探索金融科技发展，用新科技打造新金融，通过技术孵化、知识分享、项目开源，与业界同行共进。 开源项目 Talos github gitee QQ交流群：637375352 微信群：请联系管理员加入 微信公众号： 官方社区：www.kplxq.com"},{"title":"开鑫金服招聘","date":"2018-02-26T13:43:20.483Z","updated":"2018-02-26T13:43:20.483Z","comments":true,"path":"jobs/index.html","permalink":"http://kplxq.github.io/jobs/index.html","excerpt":"","text":"这么厉害！不亏是大神，你竟然发现了这个页面。既然咱们这么有缘，就来领取给你的福利吧： 招聘 Java开发工程师（测试MM干活时，负责在旁剥瓜子） 测试工程师（开发GG干活时，负责在旁加油） 弹性工作制、开放的工作氛围、一群优秀活泼的小伙伴、一个来了就不想走的工作机会…… 快拿起你手中的电话或邮箱，跟我们联系吧。邮箱：job@kxjf.com电话：025-52817677联系人：漂亮的杨MM who we are 开鑫金服是江苏省金融办批准、国家开发银行发起设立的互联网金融服务集团，互金行业标杆企业，平台累计成交已超1000亿元！引领创新，稳健前行！ 我们还是中国互联网金融协会常务理事单位，受到江苏省人民政府重点支持。 “支持实体 服务百姓”是我们一直坚持的经营理念。 Java开发工程师一、岗位职责1、测试MM干活时，负责在旁剥瓜子。2、对互联网金融系统的模块进行设计，并承担系统较复杂模块的编码，修复测试发现的问题；3、针对项目目标分解开发任务，并能安排5人以下团队的开发计划，推进计划完成；4、开发过程中，对团队成员进行技术指导，并推进开发规范落实；5、对团队成员的成果（代码、文档）进行评审，使其符合质量控制要求；6、监测系统模块在产线的运行状况，定位并处理系统出现的严重性故障。二、任职要求1、计算机相关专业，本科及以上学历； 3年以上互联网/企业级软件开发经验，3年以上J2EE/前端开发经验，1年以上系统设计经验；2、 掌握软件开发基础知识，包括软件工程、面向对象、数据结构、数据库原理等；熟悉团队管理、研发项目管理流程、软件开发规范；3、掌握软件需求分析、系统设计、设计模式相关知识；掌握开发工作常用的工具，包括文档、画图、系统设计、IDE、数据库等；4、掌握J2EE/前端开发语言及平台自带常用类库，包括Java、JavaScript、HTML、CSS等；掌握J2EE/前端常用技术框架，包括：Spring、Spirng MVC、Mybatis、Freemarker、Tomcat、JQuery等。5、了解互联网产品用户体验相关的知识；了解质量保障体系的相关知识；掌握挖掘系统问题及系统化分析与解决问题的相关理论及方法；6、有互联网金融开发背景者，参与大型项目设计或开发工作者优先。 测试工程师一、岗位职责：1、开发GG干活时，负责在旁加油。2、参与需求讨论、制定测试策略和构建测试环境；3、根据需求文档、设计文档分析测试点、测试范围，设计和编写手动和自动测试用例；4、编写和维护自动化测试脚本5、协助定位bug，配合开发人员重现和修复bug；二、职位要求：1、本科或以上学历，计算机相关专业；2、具有2年以上软件测试或开发经验,熟悉软件测试流程和测试方法；3、具有自动化测试开发经验;4、具有高度的责任心和较高的质量意识，良好的沟通协作意识，较强的问题解决能力；5、熟悉python、java者优先"},{"title":"Categories","date":"2017-12-21T14:20:50.796Z","updated":"2017-12-21T14:20:50.796Z","comments":true,"path":"categories/index.html","permalink":"http://kplxq.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-12-21T14:20:50.796Z","updated":"2017-12-21T14:20:50.796Z","comments":true,"path":"tags/index.html","permalink":"http://kplxq.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"知识是一种概率","slug":"知识是一种概率","date":"2018-04-13T07:24:51.000Z","updated":"2018-04-13T07:32:00.712Z","comments":true,"path":"2018/04/13/知识是一种概率/","link":"","permalink":"http://kplxq.github.io/2018/04/13/知识是一种概率/","excerpt":"最近在看《那些让你更聪明的科学新概念》时，了解到“基本概率”的概念: 每当一个统计学家想要基于现有证据预测事件发生的概率时，有两个必须考虑的信息点：证据本身的可靠性，我们必须计算它的可靠程度；单纯以相对发生率来计算事件发生的可能性。第二种数据其实就是基本概率。 书中给出一个容易忽略基本概率的例子，我看了答案之后发现自己算错了。","text":"最近在看《那些让你更聪明的科学新概念》时，了解到“基本概率”的概念: 每当一个统计学家想要基于现有证据预测事件发生的概率时，有两个必须考虑的信息点：证据本身的可靠性，我们必须计算它的可靠程度；单纯以相对发生率来计算事件发生的可能性。第二种数据其实就是基本概率。 书中给出一个容易忽略基本概率的例子，我看了答案之后发现自己算错了。 假设你参加了某种罕见癌症的检查。在一般人群中，这种癌症的罹患概率是1%（基本概率），而广泛的实验证明，这项检查的准确率是79%。更精确地说，尽管检查不会漏诊这项癌症，但是有21%的可能会被误诊为这个癌症，也就是所谓的假阳性。如果你接受了检查，检查结果是阳性的，那么，真的患癌的可能性是多大呢？ 这个例子可以用贝叶斯公式计算出来，应该是4.6%[^1]，我错误之处在于遗漏了“不会漏诊”这个条件，也就是如果患癌，则一定能检测到。大多数人的第一印象是从检查的可信度近80%得出确实患癌的可能性就是80%左右，这是错的。因为他们只关注到了检查的可信度，却忽视了基本概率。 另一方面，证据本身的可靠性也很重要。比如前段时间在学术圈被火热讨论的新闻“美国政治学顶级学术期刊《政治分析》宣布禁用P值”。这里的P值用于描述无效假设成立的可能性，现在学术界的一个被广泛认可的标准，是 P 值要小于 0.05。如果 P &gt; 0.05 ，别人会认为你这个结果很可能纯属巧合，根本不值得认真对待；如果 P &lt; 0.05 ，人们就说这个结果是“ 显著的 ”。 事实上，这个标准没有科学依据，只是约定俗成的，是由英国的统计学家罗纳德·费希尔（Ronald Fisher）在几十年前提出的。他当时选择了0.05这个数值，意思是 P &lt; 0.05 的结果才“值得看”。他其实认为P &lt; 0.001 才是可以接受的结论。 但问题在于，做实验想要得到 P 值小于0.001的结果，需要找太多受试者，成本实在太高。于是大家退而求其次，都默认了 0.05，其实这个标准都是很难达到的。 过去几年，在经济学、心理学等领域的论文中，P值的分布，在0.05处有明显的凸起，唯一的解释，就是有很多论文故意把P值做到了恰好在0.05以内。[^2] 所以，学习知识不仅要知其然，还要知其所以然。在《那些让你更聪明的科学新概念》中，意大利理论物理学家卡尔罗·罗威利（Carlo Rovelli）提到 本质上，知识是一种概率，这是当代实用主义哲学强调的概念。 科学就是在不断质疑中发展，知识可以随时间慢慢演化，将来新的证据和新的论证方法可能会改变现有的知识，所以也可以说很多知识是不确定的。数学物理学家弗里曼·戴森认为科学就是反叛的产物，只有反叛的心态才是科学的正确态度。而尼采也曾经提出，根本不存在什么绝对的、客观的真理。所以我们不能盲目地听从专家的意见，而应该亲自去验证知识的来源是否可靠，最好能像数学一样，一步一步地严格推理。 我们需要保持质疑精神，学会在冲突信息中随时获得新知，以应对快速变化的世界。 [1] 设A事件为患癌，B事件为检查呈阳性。P(A|B)=P(A)/P(B)P(B|A)=0.01/(10.01+0.990.21)1=0.045893[2] P&lt;0.05：科学家的隐藏动机.万维钢.2018.图中三个研究的出处可以在这里找到：http://datacolada.org/41","categories":[],"tags":[{"name":"基本概率","slug":"基本概率","permalink":"http://kplxq.github.io/tags/基本概率/"}],"keywords":[]},{"title":"代理模式及实现探究","slug":"代理模式及实现探究","date":"2018-04-08T07:14:03.000Z","updated":"2018-04-10T01:24:51.368Z","comments":true,"path":"2018/04/08/代理模式及实现探究/","link":"","permalink":"http://kplxq.github.io/2018/04/08/代理模式及实现探究/","excerpt":"前言使用过Spring并经常Debug或者熟悉Spring实现原理的开发应该知道动态代理是Spring框架实现的一大重要技术工具。 先看下图： 使用Spring依赖注入的bean通常都能看到CGLIB的标识。而我们自定义的类对象查看到对象信息基本和类定义无差。 究其原由是因为Spring依赖注入的bean并非原始的类对象，而是使用CGLIB的代理对象。 借由此本文旨在对代理模式及实现方式一探究竟。","text":"前言使用过Spring并经常Debug或者熟悉Spring实现原理的开发应该知道动态代理是Spring框架实现的一大重要技术工具。 先看下图： 使用Spring依赖注入的bean通常都能看到CGLIB的标识。而我们自定义的类对象查看到对象信息基本和类定义无差。 究其原由是因为Spring依赖注入的bean并非原始的类对象，而是使用CGLIB的代理对象。 借由此本文旨在对代理模式及实现方式一探究竟。 代理模式介绍概述因为某个对象消耗太多资源,而且你的代码并不是每个逻辑路径都需要此对象, 你曾有过延迟创建对象的想法吗? 你有想过限制访问某个对象,也就是说,提供一组方法给普通用户,特别方法给管理员用户? 以上两种需求都非常类似，并且都需要解决一个更大的问题:如何提供一致的接口给某个对象让它可以改变其内部功能,或者是从来不存在的功能? 可以通过引入一个新的对象，来实现对真实对象的操作或者将新的对象作为真实对象的一个替身。即代理对象。它可以在客户端和目标对象之间起到中介的作用，并且可以通过代理对象去掉客户不能看到的内容和服务或者添加客户需要的额外服务。 用书面术语来描述： 代理模式是常用的java设计模式。 它的特征是代理类与委托类有同样的接口。 代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。 代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。 分类按照使用场景： 远程代理（Remote Proxy）： 为一个位于不同的地址空间的对象提供一个本地的代理对象。这个不同的地址空间可以是在同一台主机中，也可是在另一台主机中，远程代理又叫做大使(Ambassador) 虚拟代理（Virtual Proxy）： 根据需要创建开销很大的对象。如果需要创建一个资源消耗较大的对象，先创建一个消耗相对较小的对象来表示，真实对象只在需要时才会被真正创建。 保护代理（Protection Proxy）： 控制对原始对象的访问。保护代理用于对象应该有不同的访问权限的时候。 智能指引（Smart Reference）： 取代了简单的指针，它在访问对象时执行一些附加操作。 Copy-on-Write代理： 它是虚拟代理的一种，把复制（克隆）操作延迟到只有在客户端真正需要时才执行。一般来说，对象的深克隆是一个开销较大的操作，Copy-on-Write代理可以让这个操作延迟，只有对象被用到的时候才被克隆。 按照实现方式： 静态代理： 在程序运行前就已经存在代理类的字节码文件。代理类和委托类的关系在运行前就确定了 动态代理： 动态代理类的源码是在程序运行期由JVM根据反射机制动态生成的。代理类和委托类的关系是在程序运行时确定的 UML图示 跟着Demo深入探究接下来我们自己动手用demo来实践一下代理模式的实现，并比较不同实现方式的区别。 公共接口及类定义： 12345678public interface TestService &#123; /** 打印入参字符串 */ void saySomething(String str); /** 返回自增+1 */ int countInt(int num);&#125; 12345678910public class TestServiceImpl implements TestService &#123; @Override public void saySomething(String str) &#123; System.out.println(str); &#125; public int countInt(int num) &#123; return (num++); &#125;&#125; 静态代理实现demo我们先看静态代理如何完成上述接口实现的代理： 123456789101112131415161718192021222324252627282930313233public class ProxySubject implements TestService &#123; // 代理类持有一个委托类的对象引用 private TestService testService; public ProxySubject(TestService testService) &#123; this.testService = testService; &#125; /** * 将请求分派给委托类执行，记录任务执行前后的时间，时间差即为任务的处理时间 * * @param taskName */ @Override public void saySomething(String something) &#123; Date startDate = new Date(); System.out.println(\"开始调用目标类时时间点：\" + startDate); // 将请求分派给委托类处理 testService.saySomething(something); Date endDate = new Date(); System.out.println(\"结束调用目标类时时间点：\" + endDate); &#125; @Override public int countInt(int num) &#123; return testService.countInt(num); &#125;&#125; 1234567public class Client &#123; public static void main(String[] args) &#123; TestService proxy = new ProxySubject(new TestServiceImpl()); proxy.saySomething(\"Hello buddy\"); &#125;&#125; 下面是上述代理执行结果： 开始调用目标类时时间点：Mon Oct 17 11:01:04 CST 2016 Hello buddy 结束调用目标类时时间点：Mon Oct 17 11:01:04 CST 2016 静态代理实现总结： 上述例子，静态代理类做的事情即是 在真实调用目标接口实现时打印接口调用的请求时间 调用目标接口 目标接口调用结束后打印请求完成时间 我们发现： 使用了静态代理。我们不需要入侵真实的目标类即可在目标对象调用时封装一套额外的逻辑。当然这是代理模式的有点，不局限于静态代理 为了实现接口的代理，我们必须要定义一个代理类实现同一个接口，在实现中显示的调用目标接口来完成代理的实现 基于这点，这也反应了静态代理实现的一大缺点： 一个代理对象服务于同一类的对象。业务类的所有方法都需要进行代理；业务类每新增一个接口，所有的代理类也要实现这个接口，增加代码维护的复杂度 JDK动态代理Demo上述静态代理的缺陷，而动态代理的特性正好可以解决。 而动态代理也有很多种实现技术手段。这一节讲讲java提供的原生动态代理： 123456789101112131415161718192021/** * JDK动态代理类 */public class ProxyHandler &#123; public static Object getPoxyObject(final Object c) &#123; return Proxy.newProxyInstance(c.getClass().getClassLoader(), c.getClass().getInterfaces(), // JDK实现动态代理，但JDK实现必须需要接口 new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object reObj = null; reObj = method.invoke(c, args); if (method.getName().equals(\"saySomething\")) &#123; System.out.println(\"at [\" + Calendar.getInstance().get(Calendar.HOUR) + \":\" + Calendar.getInstance().get(Calendar.MINUTE) + \":\" + Calendar.getInstance().get(Calendar.SECOND) + \"]\\n\"); &#125; return reObj; &#125; &#125;); &#125;&#125; 123456789101112131415161718/** * 测试客户端 */public class JDKServiceMain &#123; public static void main(String[] args) &#123; TestService service = new TestServiceImpl(); TestService poxyService = (TestService) ProxyHandler.getPoxyObject(service); System.out.println(\"\\n\\nexcute info:\\n\"); poxyService.saySomething(\"Manager Zhou: Hello, GentleSong.\"); poxyService.saySomething(\"Manager Zhou: you are KXF's dream guy.\"); poxyService.saySomething(\"Manager Zhou: Are you willing to sacrifice for the happniess of KXF's buddy?\"); poxyService.saySomething(\"GentleSong: Yes, I am.\"); &#125;&#125; 下面是上述代理执行结果： excute info: Manager Zhou: Hello, GentleSong. at [11:35:10] Manager Zhou: you are KXF&apos;s dream guy. at [11:35:10] Manager Zhou: Are you willing to sacrifice for the happniess of KXF&apos;s buddy? at [11:35:10] GentleSong: Yes, I am. at [11:35:10] JDK动态代理实现总结： 上述例子，动态代理类做的事情即是 调用目标接口 调用结束时打印请求调用完成时间 我们发现： 从JDK的实现方式看，它可以实现一类接口的的代理。 我们不需要每新增一个接口即新增一个代理类实现 我们不需要接口定义新增或删减时同时要修改代理类 但是，JDK的动态代理依靠接口实现，如果有些类并没有实现接口，则不能使用JDK代理。 CGLIB动态代理DemoJDK的动态代理是基于接口实现的。那没有接口定义的类实现如何代理嘞？ CGLIB能够解决这个问题。 12345678910111213141516171819202122232425262728/** * CGLIB动态代理类 */public class ProxyHandler &#123; public static Object getPoxyObject(Object c) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(c.getClass()); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object arg0, Method arg1, Object[] arg2, MethodProxy proxy) throws Throwable &#123; proxy.invokeSuper(arg0, arg2); if (arg1.getName().equals(\"saySomething\")) &#123; System.out.println(\"at [\" + Calendar.getInstance().get(Calendar.HOUR) + \":\" + Calendar.getInstance().get(Calendar.MINUTE) + \":\" + Calendar.getInstance().get(Calendar.SECOND) + \"]\\n\"); &#125; return null; &#125; &#125;); return enhancer.create(); &#125;&#125; 12345678910111213141516171819202122232425public class ProxyHandler &#123; public static Object getPoxyObject(Object c) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(c.getClass()); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object arg0, Method arg1, Object[] arg2, MethodProxy proxy) throws Throwable &#123; proxy.invokeSuper(arg0, arg2); if (arg1.getName().equals(\"saySomething\")) &#123; System.out.println(\"at [\" + Calendar.getInstance().get(Calendar.HOUR) + \":\" + Calendar.getInstance().get(Calendar.MINUTE) + \":\" + Calendar.getInstance().get(Calendar.SECOND) + \"]\\n\"); &#125; return null; &#125; &#125;); return enhancer.create(); &#125;&#125; CGLIB动态代理实现总结： 上述例子，动态代理类做的事情即是 调用目标接口 调用结束时打印请求调用完成时间 CGLIB实现原理： CGLIB是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强（当然这运用到了java的又一特性：修改字节码）。由于使用的是继承的方式，如果类或者方法被声明为final，将无法使用CGLIB的动态代理。 几种代理实现方式的比较上述几种代理实现方式实践之后，大家是否就粗暴的认为CGLIB动态代理的方式是最优项嘞？毕竟它解决了静态代理和JDK动态代理的缺陷。 这里我们不要这么快给出判断。同样实践得真知，下面我们用demo来测试一下几种代理实现方式的性能： 测试分为以下几个维度： 在单例模式（仅创建一次代理类）下分别执行100万、500万次静态代理、JDK动态代理、CGLIB动态代理 在多例模式（每次调用新创建代理类）下分别执行100万、500万次静态代理、JDK动态代理、CGLIB动态代理 细化测试代理对象创建、代理类执行的时耗测试 PS:在单例测试和多例测试请勿按比例比较，毕竟多例测试中不断地创建及销毁对象也是时间花销。但是不同实现方式的多例测试还是有参考性的。 具体的代码示例已上传至GitHub，链接地址为：https://github.com/huangnanxi/proxyDemo PS： demo的例子中：cglib采用的是对类的代理的调用方式（setSuperClass,invokerSuper） 基于这样的前提：比较，我们得出以下结论： 在单例模式下。JDK动态代理与CGLIB动态代理性能相差不大 在多例模式下。JDK动态代理的性能远大于CGLIB动态代理 JDK1.7的JDK动态代理性能较于JDK1.6有明显的提升 深入背后的原因是： JDK在创建代理（生成字节码时）效率远大于CGLIB JDK动态代理执行与CGLIB动态代理（类代理）执行的效率相差无几 若cglib采用的是对接口的代理的调用方式（setInterface,invoker)（大家可以修改一些demo验证一下） 结论也同cglib类代理","categories":[],"tags":[{"name":"java 动态代理","slug":"java-动态代理","permalink":"http://kplxq.github.io/tags/java-动态代理/"}],"keywords":[]},{"title":"SpringBoot2.0之WebFlux开发实战（含源码）","slug":"SpringBoot2-0之WebFlux开发实战（含源码）","date":"2018-04-03T06:06:55.000Z","updated":"2018-04-04T06:25:36.357Z","comments":true,"path":"2018/04/03/SpringBoot2-0之WebFlux开发实战（含源码）/","link":"","permalink":"http://kplxq.github.io/2018/04/03/SpringBoot2-0之WebFlux开发实战（含源码）/","excerpt":"15分钟和你一起聊一聊2.2万星超热门开源项目Spring Boot 2.0之WebFlux开发，从技术介绍、开发教程、集成案例演示到示例源代码，一网打尽。","text":"15分钟和你一起聊一聊2.2万星超热门开源项目Spring Boot 2.0之WebFlux开发，从技术介绍、开发教程、集成案例演示到示例源代码，一网打尽。 背景知识Spring Boot2.0北京时间3月1日，Spring Boot 2.0正式发布Release版本。作为Spring生态中重要的开源项目,Spring Boot旨在帮助开发者更容易的创建基于Spring的应用程序和服务。经历了4年的发展，Spring Boot已经拥有了22000多star，16000次Commits，贡献者超过400多名的超热门开源项目。其中刚发布的2.0版本是自2014年4月1日发布的1.0版本以来第一次重大修订，也是首个提供对Spring Framework 5.0支持的GA稳定版本，2.0带来了很多新的特性✓基于Spring 5构建的Spring Boot 2.0，通过使用Spring WebFlux 提供了响应式Web编程支持；✓基于Java 8（最低标准），支持Java 9；✓支持HTTP/2;Spring Boot的Web容器选择中Tomcat、Undertow和Jetty均已支持HTTP/2。HTTP/2较HTTP/1.1在性能上有显著提升，页面加载时间降低了50%，详见Java 9和Spring Boot2.0纷纷宣布支持的HTTP/2到底是什么。其余新特性不在此赘述，详见Spring Boot 2.0 Release Notes。 Spring WebFluxSpring WebFlux是一个非阻塞的函数式Reactive Web框架，可以用来构建异步的、非阻塞的、事件驱动的服务，在伸缩性方面表现非常好。名称中的Flux来源于Reactor中的类Flux。 众所周知Spring MVC是同步阻塞的IO模型，资源浪费相对比较严重，当我们在处理一个耗时的任务时，例如上传一个较大的文件时，服务器的线程一直在等待接收文件，这期间什么也做不了，等到文件接收完毕可能又要写入磁盘，写入的过程线程又只能在那等待，非常浪费资源。而Spring WebFlux是这样做的，线程发现文件还没接收好，先去做其他事情，当文件接收完毕后通知该线程来处理，后续写入磁盘完毕后再通知该线程来处理，通过异步非阻塞机制节省了系统资源，极大的提高了系统的并发量。因此对于微服务下的IO密集型的Service来说，WebFlux是一个不错的选择。 左边是传统基于Servlet的Spring Web MVC框架，右边是Spring Framework 5.0引入的基于Reactive Streams的Spring WebFlux框架，从上到下依次是Router Functions、WebFlux和Reactive Streams三个新的组件。● Router Functions：对应@Controller、@RequestMapping等标准的Spring MVC注解，提供了一套函数式编程的API，用于创建Router、Handler和Filter。● WebFlux：核心组件，用于协调上下游各个组件提供响应式编程的支持。● Reactive Streams：一种支持Backpressure的异步数据流处理标准，主流实现有RxJava和Reactor，Spring、WebFlux默认集成的是Reactor。Backpressure是一种反馈机制，当数据的发布速度超过处理速度时，消费者需要决定缓存还是丢弃，在响应式编程中，决定权交回给了发布者，消费者只需根据自身处理能力向发布者请求相应数量的数据。●Web容器：Spring WebFlux既支持Tomcat、Jetty等传统容器（前提是支持Servlet3.1+）,又支持Netty、Undertow等异步容器。只能运行在Servlet 3.1+容器上，是因为3.1规范支持异步处理，该功能主要针对业务处理较耗时的情况，可以减少服务器资源占用，提高并发处理速度。 Spring WebFlux实战WebFlux工程创建本文默认开发环境是JDK8，开发工具是IntelliJ IDEA。下面我们基于Spring Boot 2.0创建一个WebFlux工程，操作步骤非常简单：1)点击Create New Project,创建一个新的项目； 2)选择Spring Initializr,并配置JDK版本为1.8，Initializr Service UR按默认配置为https://start.spring.io; 3)在metadata页配置工程包名等信息，其中type项目构建方式选择默认值，使用maven进行项目构建； 4)在Dependencies页，我们先将Spring Boot版本设置为2.0.0，可以看到下方有很多选项可以选择，每个选项代表一个组件，这里选择“Web”-&gt;“Reactive Web”组件。可以看到下方提示，Reactive Web development with Netty and Spring WebFlux，即通过Reactive Web构建一个WebFlux应用服务； 5)最后配置下工程名称和项目路径，即完成了Spring WebFlux应用的创建。 默认的demo工程pom中只包括webflux和reactor等组件依赖。 Hello World应用开发下面通过编写Handler和Router Functions来实现hello world程序。1)编写Hello world handler，该类相当于Spring Web中的Service bean； 2)将Hello world handler注册到路由上，类似于Spring Web中的Controller类的创建。除了新的Router Functions接口，Spring WebFlux同时支持使用老的Spring MVC注解声明Reactive Controller。 3)接着运行DemoApplication的main方法，即完成了服务启动，这里默认采用了Netty作为reactor的底层容器启动。 最后访问http://127.0.0.1:8080/hello，返回hello world即表示服务启动和访问成功。 注册登录应用开发需要注意目前支持reactive编程的数据库只有MongoDB，Redis，Cassandra，Couchbase，而JDBC与JPA的事务是基于阻塞IO模型的，并不是自然支持reactive编程风格，需要等待Spring Data Reactive升级IO模型才能支持相关数据库事务的使用。 这里以Redis作为数据库，实现一个简单的用户注册登录功能。1)首先配置Spring Data Reactive Redis，默认指向本地6379端口的Redis； 2)编写用户注册登录handler,主要通过RedisConnection进行数据入库和查询操作，并将业务处理结果以Json格式进行返回。 Uri中的参数可以通过ServerRequest.bodyToMono来获取。返回的类型Mono可以通过ServerResponse来创建，主要包括以下几步：a) 状态码方法，可以使用现成的也可以自定义，例如成功的状态码： b) ContentType(MediaType var1)返回的内容类型是MediaType类型；c) 最后是返回的内容： 一般常用body()来放入返回的内容，如使用BodyInserters的构建方法fromObject()。3)添加注册登录路由,将url路由给具体的handler来进行处理; 路由关系创建主要通过RouterFunctions来创建route, 其中RequestPredicate和HandlerFunction都是函数式接口，HandlerFunction接受一个ServerResponse的子类返回Mono,可以把这个对象认为是实际处理逻辑的部分。 下面我们来验证下程序的运行情况：1)首先运行服务，然后通过postman发送用户注册请求；2)发送注册请求后，除了前台返回{“message”:”successful”},同时可以查看Redis中保存的注册信息； 3)接着用刚注册的信息发起登录请求，可以看出返回结果为登录成功。 至此即完成了一个简单的基于Spring WebFlux和Redis的用户注册登录功能开发。 分析总结通过以上介绍，可以看出基于SpringBoot进行WebFlux开发即简单又高效。下面对WebFlux中几个关键语法点进行介绍：首先简单说下Reactor的两个关键概念，Mono和Flux是Reactor中的流数据类型，Mono是一个用来发送0或者单值数据的发布器，Flux可以用来发送0到 N 个值。它们表示在订阅这些发布服务时发送的数值流。如下图中getUserById()返回一个Mono表示其在数据可用的情况下发送0个或者单个用户，getUsers()返回一个用户列表的Flux实例，表示其发送0到多个用户数据。 上文提到的handler处理类相当于服务bean,一般用来编写业务功能，其中返回的ServerResponse类似Spring Web中的ResponseEntity用来封装响应数据，包括状态码、HTTP头等信息，它包含了ok(),notFound()等方法，用来创建不同类型的响应信息。如上图的UserRepository.getUserById()返回一个Mono，而ServerResponse.ok().body(Mono.just(user), User.class) 将这个Mono转成Mono,这代表在ServerResponse可用时候发送响应的流。ServerResponse.notFound().build()返回一个Mono对象，当给定的pathVariable中找不到对应用户信息时返回404的服务器响应信息。 Spring WebFlux除了对响应式http的支持外，还包括服务端推送事件（Server Sent Events,SSE）、WebSocket客户端和服务端的支持。其中服务端推送事件允许服务器不断地推送数据到客户端，它的实现非常简单，只需要返回对象类型配置成Flux,就会自动按照SSE规范要求的格式发送响应。在命令式的编程风格中，线程的执行会被堵塞，直到接收到数据。这使得数据在实际返回之前线程必须进行等待。而在Reactive编程中，我们定义了一个流，用来发送数据以及数据返回时所执行的操作。使用这种方法线程不会被堵塞的。当数据返回时框架会选择一个可用的线程进行下一步处理，这就体现出异步非阻塞模式的优势所在。因此响应式编程能带来更快处理速度，更高硬件利用率的未来选择。 参考资料 https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-fn-handler-functions https://coyee.com/article/12086-spring-5-reactive-web https://zhuanlan.zhihu.com/p/30813274 https://github.com/hantsy/spring-reactive-sample#spring-data-redis https://www.ibm.com/developerworks/cn/java/spring5-webflux-reactive/index.html 作者介绍刘海东，供职于开鑫金服，任移动端架构师、销售平台技术专家，主要方向是Java Web、Android、shell和C++，精力充沛，爱好广泛。","categories":[],"tags":[],"keywords":[]},{"title":"见女神的极简之途——BFS算法","slug":"见女神的极简之途——BFS算法","date":"2018-03-16T05:55:27.000Z","updated":"2018-04-04T06:28:44.845Z","comments":true,"path":"2018/03/16/见女神的极简之途——BFS算法/","link":"","permalink":"http://kplxq.github.io/2018/03/16/见女神的极简之途——BFS算法/","excerpt":"三月，空气中弥漫着恋爱的味道，程序员哧溜君忽然接到女神电话要去见丈母娘了（喜闻乐见），女神一再叮嘱头一次得好好地准备准备，而且不能迟到： 到【艾欧尼亚】做头发； 到【德玛西亚】买给岳父的保养品； 到【扭曲丛林】买给丈母娘的护肤品； 到【皮城警备】买给准小侄子的玩具； 最后才能到【女神家】……每个地方的距离都很远，如何合理地规划路线？这相似的场景，程序员哧溜君不觉笑了起来……","text":"三月，空气中弥漫着恋爱的味道，程序员哧溜君忽然接到女神电话要去见丈母娘了（喜闻乐见），女神一再叮嘱头一次得好好地准备准备，而且不能迟到： 到【艾欧尼亚】做头发； 到【德玛西亚】买给岳父的保养品； 到【扭曲丛林】买给丈母娘的护肤品； 到【皮城警备】买给准小侄子的玩具； 最后才能到【女神家】……每个地方的距离都很远，如何合理地规划路线？这相似的场景，程序员哧溜君不觉笑了起来…… BFS是什么BFS全称为Breadth-First-Search，即⼴度优先遍历算法，是经典的连通图遍历算法。简单的说， BFS是从根结点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问则算法结束。 换成算法语来描述的话就是： 首先将根节点放到待遍历的队列Q中； 循环从Q中获取待遍历的节点N； 获取节点N通过条边可以到达的所有节点集合L； 循环遍历节点集合 L，判断L的元素是否存在于已遍历的节点集合C中； 已存在集合 C中，则忽略； 不存在集合 C中，则将此节点加⼊到队列 Q中； 循环遍历Q直到Q为空则遍历结束。（没看懂没关系，后面有详细讲解呢，哧溜~） BFS用来做什么BFS作为图遍历的基础算法，它的算法思想被很多高级算法借鉴和使用。 Dijkstra单源最短路径算法和Prim最小生成树算法都采用了和宽度优先搜索类似的思想。 我们可以对哧溜君见丈母娘之路进行建模，A点为哧溜君所在之处，B点为目的地，找到A与B之间的最短路径。 针对上述问题有很多算法方案可以解决，其中BFS算法是较简单和直接的方案。以A节点为根节点通过BFS遍历其他节点，直到遍历到B节点为止，这种理想情况下说起来还是比较简单的。 但是不要认为这样就可以完美解决这个问题，完美的解决方案还需要考虑以下因素： 哧溜君在行走的过程中，如何避免遇到前女友； 在那么多的目的地之中寻找最先去的目的地； 在哧溜君去往目的地的路上，判断是否需要翻墙、踩水坑、闯红灯； BFS怎么做以上都是理论知识，读起来可能比较枯燥。我们举个例子来进一步说明BFS算法。给定一个图，从图中一个节点出发，通过BFS遍历所有能遍历的节点。 图的初始状态如下： 初始状态，从顶点 1开始，队列 ={1}； 访问1的邻接顶点， 1出队变⿊， 2,3⼊队，队列 ={2,3,}; 访问2的邻接结点， 2出队，4⼊队，队列 ={3,4}; 访问4的邻接结点， 4出队，队列 ={空}; 经过上述遍历过程，我们已经通过BFS算法找到所有节点1可以到达的节点，进一步可以分析出节点1到每个节点的最短距离，哈哈哈哈哈…… 程序员哧溜君经过一番计算后， 终于……终于……从梦中醒来了。程序员怎么可能有女朋友啊，而且还是女神！还是去程序里继续new对象吧。","categories":[],"tags":[{"name":"算法 BFS","slug":"算法-BFS","permalink":"http://kplxq.github.io/tags/算法-BFS/"}],"keywords":[]},{"title":"别再低效学习了，快构建自己的知识体系吧！","slug":"别再低效学习了，快构建自己的知识体系吧！","date":"2018-03-09T05:42:47.000Z","updated":"2018-04-04T05:52:20.803Z","comments":true,"path":"2018/03/09/别再低效学习了，快构建自己的知识体系吧！/","link":"","permalink":"http://kplxq.github.io/2018/03/09/别再低效学习了，快构建自己的知识体系吧！/","excerpt":"我们每天都在主动或被动地接受各类文章的轰炸，点赞、转发、收藏、保存……然后呢，我们得到了什么？在工作中我们遇到了各种各样的问题，然后主动地去搜索资料并最终成功解决了，然后呢，我们学到了什么？在面对层出不穷的新技术、新知识点时，我们很努力很努力地去学习，却始终有种力不从心的感觉，甚至认为自己的学习能力下降，这是因为什么？","text":"我们每天都在主动或被动地接受各类文章的轰炸，点赞、转发、收藏、保存……然后呢，我们得到了什么？在工作中我们遇到了各种各样的问题，然后主动地去搜索资料并最终成功解决了，然后呢，我们学到了什么？在面对层出不穷的新技术、新知识点时，我们很努力很努力地去学习，却始终有种力不从心的感觉，甚至认为自己的学习能力下降，这是因为什么？ 一、什么是知识体系？知识体系，其实大家应该不算陌生了，通俗点的解释就是把一些零碎的、分散的、相对独立的知识概念或观点加以整合，使之形成具有一定联系的知识系统。这种系统就像是一棵树，每片叶子都是独立的，但树干把它们联系在一起，形成了体系，最典型的例子就是我们学生时代做的那些教辅资料，它们的每章末都会有自己的章末小结，对前一章的知识点进行整合，即是最常见的知识体系的构建了。 二、低效的知识学习方式构建知识体系的原理大家都懂，但真正实施起来又谈何容易，世界上的各类知识成千上万，又赶上互联网数据大爆炸的时代，知识早已不再是以“点状”或者“树状”的形态呈现，而是变成了一张密密麻麻纵横交错的“网”，以个人的能力将它们内化成知识体系几乎成了一种“吃力不讨好”的行为。 早些年在腾讯cdc博客曾流传过这样一张图（原作者： hsiang），用于描述我们日常生活中最常见的低效的知识管理现象。 知识收集为中心的学习观念每天热衷于各类知识的收集，比如在知乎上看到好的回答就想点收藏，但收藏之后又不会多看一眼，潜意识里不愿花较多的时间在知识的消化上，又偏偏是收集成瘾，最终导致采集的知识总量越来越大，逐渐产生一种时间不够用的错觉，最终在知识的海洋里迷失自我，整日忙忙碌碌、碌碌无为。 囫囵吞枣，不求甚解的学习观念“我懂了”与“我会用”其实是两个概念，很多时候我们都会高估自己实际运用的能力，做什么事都喜欢求大求全，自以为积累的各门类的知识越完整越好、越“成套”越好……殊不知这样建立起来的知识体系往往看似高大全，实则都是“纸老虎”，经不起实战的考验。 应当以自己的应用场景去架构自己的知识世界所谓的“应用场景”，其实理解起来很简单，就是我们掌握知识也好，建立体系也罢，其根本目的还是为了学以致用，你完全可以依据自己的专业或者工作建立一套高实用性的知识体系，让你可以随时能从中提取信息，并且运用到自己的生活和学习中。 三、建立知识体系的一般办法 明确知识体系的主题和用途简而言之，在构建自己的知识体系之前，你务必要明确自己体系的主题和目标，提醒自己“我的知识体系是什么，它的用途是什么，我又为什么要建立它？ 通过下图的金字塔，我会发现我自己现在每天正在学习和坚持的是在哪个区间里面： 总之一句话，学那些让自己变得更加专业的知识，让自己的专业知识金字塔变得更高。 找到获取知识的途径 书本： 针对某一领域，进行快速阅读和主题阅读，可以快速掌握某一领域的基础知识，形成最基础的知识框架，另外每本书一般都会有参考资料，这些也是很好的知识来源，只要你细心，完全可以按图索骥，从中找到适合自己建立“体系”的内容。 课堂： 这里的课堂既包括现实中的上课，也包括网络视频课程，像网易云课堂、中国MOOC等网站都是你获取知识的有效途径。 网络： 互联网时代，网络已然成为我们生活的必须品，只有你好好利用网络，其实能找到适合你“知识体系”的内容，这是你主动学习的一大“法宝”。 随时留心生活的点滴： 永远不要把知识累积全部放到主动学习上，有的时候生活当中的一本随手翻翻的书、一页无意中浏览到的网页、一次好友亲人之间的聊天，如果你足够敏感，都可以成为你知识体系中重要知识的来源。 知识的整理与分类知识的淘汰更新非常重要，我们是知识工作者，不是历史学家，很多信息甚至在我们收集到手之后就已经过期了。所以果断抛弃我们当下用不到的知识，用断舍离的方式来提醒我不要囤积“能用”但是当下对我没用的知识垃圾。 有了前面所说的主题和途径，你就可以按照逻辑和层次，分出尽量详细的项目类别了，这期间你既可以用手写笔记的形式整理，也可以利用网络管理资源，像有道云笔记、印象笔记、为知笔记、evernote等笔记类软件进行整合，专门建立一些“笔记本”，用你的“知识项目”来命名，然后把你的知识点（文字、图片、其他媒体）按照名称，作为笔记归纳进你的知识体系之中。 知识的输出与运用教是最好的学习，实现90%的知识转化，分享是最好的方式。 总结1、建立自己的知识体系，最重要的是思维上的转变，纠正“以知识的收集为中心”的学习观念以及“囫囵吞枣、不求甚解”的学习方法，改变低效的个人知识管理模式，应当以自己的应用场景去架构自己的知识世界。 2、纠正了思维上误区，还要掌握构建知识体系的一般方法。你需要在体系建立之前明确它的主题和用途，不在无关的内容上浪费自己宝贵的时间，之后你要学会利用身边的各种资源获取知识，随时留心生活中的点点滴滴，一举一动、一草一木都可以是获取知识的来源。 3、有了来源，还要学会知识的整理和分类，可以按照逻辑和层次，分出尽量详细的项目类别，期间充分利用像有道云笔记这种网络笔记类软件，分门别类，不断补充。 4、知识的输出和运用是我们建立知识体系的最终目的，可以用“费曼技巧”等方式检验自己的学习成果， 只有读进去能表达出来，才算是真正的吸收，从而获得难以替代的成就感。 5、有了体系也千万不要墨守成规， 因为你会不断地遇到新的信息，必然会对原来的结构造成影响，这时候你要及时把握学术动态，更新知识体系，一定不能让自己的大脑僵化，而是要打破原来的体系不断对新的事物进行接受。 开普勒鑫球-贾克斯收集、整理。","categories":[],"tags":[{"name":"学习方法","slug":"学习方法","permalink":"http://kplxq.github.io/tags/学习方法/"}],"keywords":[]},{"title":"Elasticsearch依赖包冲突的解决方案","slug":"Elasticsearch依赖包冲突的解决方案","date":"2018-01-30T03:04:09.000Z","updated":"2018-02-28T01:26:48.883Z","comments":true,"path":"2018/01/30/Elasticsearch依赖包冲突的解决方案/","link":"","permalink":"http://kplxq.github.io/2018/01/30/Elasticsearch依赖包冲突的解决方案/","excerpt":"Guava是谷歌开源的一个工具类库，有很多实用的工具类广为流传，在Java1.7往后的版本也有很多基于Guava类库的工具类进行的优化，很多中间件也依赖Guava用来优化代码，但是Guava的版本升级很快，大版本号升级时，有些类库是不向下兼容的，本文要说的就是在Elasticsearch和HBase中Guava版本不一致导致的依赖冲突的解决方案","text":"Guava是谷歌开源的一个工具类库，有很多实用的工具类广为流传，在Java1.7往后的版本也有很多基于Guava类库的工具类进行的优化，很多中间件也依赖Guava用来优化代码，但是Guava的版本升级很快，大版本号升级时，有些类库是不向下兼容的，本文要说的就是在Elasticsearch和HBase中Guava版本不一致导致的依赖冲突的解决方案 Talos的应用架构中，我们是在talos-storage组件中将链路日志的数据存储到HBase和Elasticsearch，在开发过程中，遇到ES和HBase因依赖的Guava包冲突导致工程启动报错。 HBase版本号：1.2.0 (依赖Guava12.0.1)Elasticsearch版本号：2.4.0 (依赖Guava10.0.1)Java：1.7 Elasticsearch官方对于这个问题还是很重视的，关于是否要移除Guava依赖，在github issue上还有一些激烈的讨论，附上issue链接，因为开发者的重视，在Elasticsearch5.0.0版本的release note中，公开已经将对guava的依赖去掉了。不过在我们开发talos-storage的时候，Elasticsearch还没有发布5.0.0的Release，因此当时是参考官网的一篇指导文档To shade or not to shade，官网是以joda为例，guava的shade方式也如出一辙。 后面配置文件很长，所以先给出结论：1、如果你现在还处于调研阶段，遇到了ES和HBase或其他组件对Guava的依赖冲突，建议转去调研Elasticsearch的最新RELEASE版本。2、如果你和我一样，产线已经部署并运行着Elasticsearch5.0.0以下的版本，那你有两种选择，一种是将Elasticsearch升级到5.0.0，另一种是使用shade的方式，以下将分别介绍这两种方案的实施步骤。 升级Elasticsearch (2.x至5.x)Elasticsearch的大版本升级是需要停止所有节点后再重启的，不支持波浪升级，在升级之前需要做的几件事：1、使用Elasticsearch Migration Plugin插件来排除潜在风险。2、产线环境搞之前一定要在测试环境先验证成功。3、备份数据，备份数据，备份数据。 以下是升级的步骤：1、为避免一个节点关闭后分片之间的数据复制导致的I/O浪费，在关闭节点前先Disable shard allocation 123456PUT _cluster/settings&#123; &quot;persistent&quot;: &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot; &#125;&#125; 2、将flush改为同步操作，分片的恢复会快很多。 1POST _flush/synced 3、逐个节点关闭并升级，这个看你最初安装es是什么方式的，如果是参考taolo的Elasticsearch部署文档，那依然参考这篇博客，只需在下载时使用最新RELEASE的即可。4、升级所有的插件，用elasticsearch-plugin脚本即可。5、启动各个节点，待所有节点均已启动成功，并且status返回的是yellow，表明所有分片已经恢复。6、重新启用分片分配123456PUT _cluster/settings&#123; &quot;persistent&quot;: &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot; &#125;&#125; 7、这时候Elasticsearch已经升级完成了，并可以正常工作了，不过为了集群更快的恢复，建议还是等到status返回green，再进行后续工作。 不升级Elasticsearch，使用shade的方式避免冲突坐享其成talos-storage组件已经实践过并已经发布RELEASE的一个talos-es-shaded，将对elasticsearch的依赖改为如下即可： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;12.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.kxjf.talos&lt;/groupId&gt; &lt;artifactId&gt;talos-es-shaded&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 自力更生创建一个新的maven工程，pom文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;groupId&gt;my.elasticsearch.test&lt;/groupId&gt;&lt;artifactId&gt;es-shaded&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;properties&gt; &lt;elasticsearch.version&gt;2.0.0-beta2&lt;/elasticsearch.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.plugin&lt;/groupId&gt; &lt;artifactId&gt;shield&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;elasticsearch-releases&lt;/id&gt; http://maven.elasticsearch.org/releases &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;relocations&gt; &lt;relocation&gt; &lt;pattern&gt;org.joda&lt;/pattern&gt; &lt;shadedPattern&gt;my.elasticsearch.joda&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;relocation&gt; &lt;pattern&gt;com.google.guava&lt;/pattern&gt; &lt;shadedPattern&gt;my.elasticsearch.guava&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;/relocations&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot; /&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在执行mvn clean install 后，依赖将变成 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;my.elasticsearch.test&lt;/groupId&gt; &lt;artifactId&gt;es-shaded&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;12.0.1&lt;/version&gt;&lt;/dependency&gt; 比如你还要使用2.9.2版本的joda，照常引入org.joda.time.DateTime即可，若你要使用shaded版本中的Joda，引入my.elasticsearch.joda.time.DateTime即可，不过这种做法并不被建议哈，代码如下： 12345CodeSource codeSource = new org.joda.time.DateTime().getClass().getProtectionDomain().getCodeSource();System.out.println(&quot;unshaded = &quot; + codeSource);codeSource = new my.elasticsearch.joda.time.DateTime().getClass().getProtectionDomain().getCodeSource();System.out.println(&quot;shaded = &quot; + codeSource); 将会输出： 12unshaded = (file:/path/to/joda-time-2.1.jar &lt;no signer certificates&gt;)shaded = (file:/path/to/es-shaded-1.0-SNAPSHOT.jar &lt;no signer certificates&gt;) End.","categories":[],"tags":[{"name":"elasticsearch guava","slug":"elasticsearch-guava","permalink":"http://kplxq.github.io/tags/elasticsearch-guava/"}],"keywords":[]},{"title":"震惊！机器人竟然真的开战了，有图有真相！","slug":"震惊！机器人竟然真的开战了，有图有真相！","date":"2018-01-24T07:38:08.000Z","updated":"2018-02-08T07:49:52.548Z","comments":true,"path":"2018/01/24/震惊！机器人竟然真的开战了，有图有真相！/","link":"","permalink":"http://kplxq.github.io/2018/01/24/震惊！机器人竟然真的开战了，有图有真相！/","excerpt":"是我把他带到这个世界， 一个能够思考与感知的机器人。 现在我宣布： 你被终结了！","text":"是我把他带到这个世界， 一个能够思考与感知的机器人。 现在我宣布： 你被终结了！ 2018年1月24日下午，开普勒鑫球杯机器人编程大赛正式开赛，共有20个团队参加，让我们再来一起回顾下吧。（注：源码已开放下载，请拖到文末） 赛前，小伙伴们交流各自机器人的编程算法，设计思想。抢血包、躲地雷，锁定追踪攻击…… 比赛现场，观战。有一个猥琐的机器人“梵高”……，应了那句话：要么不干，要么干出风格！大写的服啊！后续将邀请他来讲讲他诡异的算法。 经过小组赛、晋级赛、决赛等一系列激烈的PK后，各大奖项终于出炉了，一起来看看吧。 ———— 我是分割线 ———— 特别奖获得者：由向日葵、暴风、秋名山、堡垒四个团队获得。 猜猜以上哪个团队创造了机器人“梵高” 第三名！团队名：rookie，参赛机器人：瓦力 第二名！团队名：极限特工，参赛机器人：代号47 第一名！团队名：A&amp;V，参赛机器人：A&amp;V 胜利者的拥抱！爱的拥抱！全场欢呼“在一起”！ 特别感谢：南溪同学 。感谢南溪同学编写了机器人编程大赛的沙盒，为大家提供了一个技术切磋、华山论码的机会，无码诚可贵，有码价更高啊！ 附：所有参赛团队及参赛机器人 比赛沙盒源代码已开源，微信公众号回复“机器人”，即可获取源代码地址。 后续文章会讲解关于机器人PK过程中用到的一些经典的编程思想、编程算法，欢迎关注，交流。也欢迎各位提交自己的机器人，一起来PK！点击公众号菜单“关于我们”即可联系我们哦！","categories":[],"tags":[],"keywords":[]},{"title":"怎样监控Kubernetes容器","slug":"怎样监控Kubernetes容器","date":"2018-01-17T03:53:50.000Z","updated":"2018-01-19T04:47:23.083Z","comments":true,"path":"2018/01/17/怎样监控Kubernetes容器/","link":"","permalink":"http://kplxq.github.io/2018/01/17/怎样监控Kubernetes容器/","excerpt":"怎样监控Kubernetes容器一、容器的运行方式与VM和HOST的差异Kubernetes是现在最流行的容器编排系统，容器与VM和HOST有着显著不同。怎样对k8s平台上的容器进行监控？首先需要注意容器的运行方式与VM和HOST的不同：","text":"怎样监控Kubernetes容器一、容器的运行方式与VM和HOST的差异Kubernetes是现在最流行的容器编排系统，容器与VM和HOST有着显著不同。怎样对k8s平台上的容器进行监控？首先需要注意容器的运行方式与VM和HOST的不同： 运行实例从宏观层面迁移到微观层面容器运行在私有网络中，通常情况下与外部网络隔离。怎样从外部网络进入到容器私有网络、获取容器的监控数据？ 运行实例从静态、长生命周期转变成动态、短生命周期HOST和VM一般是静态IP地址，一旦开机、长期运行。而容器的IP是动态分配的，其创建、销毁、扩容、缩容非常频繁。如何及时发现新创建的容器、获取到它们的监控数据、并在仪表盘上恰当的展现出来？ 二、容器监控方案概述为了解决上述问题，kubernetes、promethues、influxdata等开源组织相继发布了一些容器监控工具和方案。例如：kubernetes 的 heapster+influxdb+grafana，prometheus的prometheus+alertmanager，influxdata的telegraf+influxdb+kapacitor。 我采用的是第一种，即： heapster+influxdb+grafana，实现简单、效果较好。 其中，heapster是k8s容器状态的收集、导出工具，influxdb是一种时序数据库，grafana是一种数据展示和报警系统。 heapster能导出当前时间点的所有容器的状态信息，解决了容器监控信息的采集和导出问题；grafana是功能强大的数据展示和报警工具，它的展示系统支持变量、模板、正则匹配、标签等功能，能把瞬息万变的容器信息有效组织、展示出来，报警系统支持多种方式、还可以基于webhook自己开发，实现短信报警等功能。 三、容器监控部署概述（由于字数限制，不详述，具体请参考官方文档；所有组件都基于容器部署） 部署influxdbhttps://github.com/influxdata/influxdb 部署heapsterhttps://github.com/kubernetes/heapster/tree/master/deploycommand加sink参数，包含influxdb的地址、用户名、密码，例如：–sink=influxdb:http://influxdb.default:8086?db=heapster&amp;user=heapster&amp;pw=1234 部署grafanahttps://github.com/grafana/grafana部署后请设置数据源datasource，加入influxdb。 四、设置仪表盘Grafana的仪表盘也就是监控数据的展示界面，可以自己设计，还可以导出共享给别人。我设计了一个容器监控的仪表盘，共享在grafana网站上，地址是：https://grafana.com/dashboards/3649 在namespace下拉框可以选择k8s容器的命名空间，在pod_name下拉框可以选择容器的匹配名称（前面几个字符或者全名都可以）。 五、建立容器报警我共享的仪表盘含有两个变量：namespace和pod_name，这样的仪表盘叫：模板。Grafana目前不支持在模板里创建报警。为了创建报警，我们需要再建一个不带变量的仪表盘，然后在时序图的Alert菜单里设置报警，设置报警阀值、通道、内容等信息： 六、建立报警一览图Grafana自带一个报警管理页面： 我们可以设计一个更清楚的报警一览图，可参考我共享的模板，地址是：https://grafana.com/dashboards/3489","categories":[],"tags":[],"keywords":[]},{"title":"机器人编程大赛的沙盒源代码正式开放提供下载啦！","slug":"机器人编程大赛的沙盒源代码正式开放提供下载啦！","date":"2018-01-15T08:25:12.000Z","updated":"2018-01-16T09:17:45.969Z","comments":true,"path":"2018/01/15/机器人编程大赛的沙盒源代码正式开放提供下载啦！/","link":"","permalink":"http://kplxq.github.io/2018/01/15/机器人编程大赛的沙盒源代码正式开放提供下载啦！/","excerpt":"怎样才能搞一个又有趣又能提升技术能力的活动？程序员年底团建怎么搞？想搞编程大赛，没有好的方案，没有沙盒？","text":"怎样才能搞一个又有趣又能提升技术能力的活动？程序员年底团建怎么搞？想搞编程大赛，没有好的方案，没有沙盒？ 开普勒鑫球杯机器人编程大赛的沙盒源代码（V1.0）正式对外开放，提供下载啦。 用你的思想控制硝烟弥漫的战场，利用牛逼的算法，牛逼的策略，创造属于你自己的无敌机器人！抢血包！躲地雷！群战！看看究竟谁才是You Xi Zhi King吧！ 在2.0版本的沙盒中，还支持多人PK、组队PK模式，支持传送门、天神下凡、凌波微步等多种更为先进的技能噢，后续也会开放源码，尽情继续关注。 QQ交流群：637375352微信公众号回复“机器人”，即可获取源代码地址。 参考阅读：玩游戏的逆天新姿势，屌炸天啊！！","categories":[],"tags":[{"name":"机器人编程","slug":"机器人编程","permalink":"http://kplxq.github.io/tags/机器人编程/"}],"keywords":[]},{"title":"玩游戏的逆天新姿势，屌炸天啊！！","slug":"玩游戏的逆天新姿势，屌炸天啊！！","date":"2018-01-12T08:24:44.000Z","updated":"2018-01-16T09:18:19.397Z","comments":true,"path":"2018/01/12/玩游戏的逆天新姿势，屌炸天啊！！/","link":"","permalink":"http://kplxq.github.io/2018/01/12/玩游戏的逆天新姿势，屌炸天啊！！/","excerpt":"打游戏，可以有很多姿势，比如下面这样的：","text":"打游戏，可以有很多姿势，比如下面这样的： 但对于程序员来说，这些还是太低级太Low啊，有本事，有本事你不要用手啊！！！你不要用手啊！！！不用手啊！！！手啊！！！啊！！！叮~叮~叮~ 就是下面酱紫滴！开普勒鑫球杯机器人大战编程竞赛，用你的思想控制硝烟弥漫的战场，利用牛逼的算法，牛逼的策略，创造属于你自己的无敌机器人！抢血包！躲地雷！群战！1月17日，现场PK，看看究竟谁才是You Xi Zhi King，参加还有大奖拿噢，是不是很兴奋！！！！ 最最重要的是，下周一（01月15号），我们还会开放机器人挑战赛沙盒的 源 代 码，一起来群P啊！敬请关注！（现场比赛暂时只限内部，欢迎关注开普勒鑫球，后续还有更多有趣的活动，还有福利拿噢）","categories":[],"tags":[{"name":"机器人编程","slug":"机器人编程","permalink":"http://kplxq.github.io/tags/机器人编程/"}],"keywords":[]},{"title":"从一段臭名昭彰却又广为人知的代码说起……","slug":"从一段臭名昭彰却又广为人知的代码说起……","date":"2018-01-10T08:24:26.000Z","updated":"2018-01-16T09:18:42.081Z","comments":true,"path":"2018/01/10/从一段臭名昭彰却又广为人知的代码说起……/","link":"","permalink":"http://kplxq.github.io/2018/01/10/从一段臭名昭彰却又广为人知的代码说起……/","excerpt":"作为一名程序猿，谁没挖过几个坑，坑坑都是泪啊…… ，农历年的年底了，鸡年要走了，狗年要来了，各位码工动代码时千万悠着点，三思而后行，可不能鸡飞狗跳啊！2018年，愿世界和平，天下无坑！今天就来和大家聊聊一个简单的并发编程的坑，","text":"作为一名程序猿，谁没挖过几个坑，坑坑都是泪啊…… ，农历年的年底了，鸡年要走了，狗年要来了，各位码工动代码时千万悠着点，三思而后行，可不能鸡飞狗跳啊！2018年，愿世界和平，天下无坑！今天就来和大家聊聊一个简单的并发编程的坑， 各位编码过程中，遇到过什么坑，欢迎留言，交流分享！","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://kplxq.github.io/tags/并发编程/"}],"keywords":[]},{"title":"开普勒鑫球全链路监控系统Talos正式开源","slug":"开普勒鑫球全链路监控系统Talos正式开源","date":"2017-12-15T15:17:13.000Z","updated":"2018-01-06T11:36:45.688Z","comments":true,"path":"2017/12/15/开普勒鑫球全链路监控系统Talos正式开源/","link":"","permalink":"http://kplxq.github.io/2017/12/15/开普勒鑫球全链路监控系统Talos正式开源/","excerpt":"2017年12月24日，开普勒鑫球的开源社区正式对外发布了其首个开源项目- Talos。","text":"2017年12月24日，开普勒鑫球的开源社区正式对外发布了其首个开源项目- Talos。 Talos是一个大数据全链路监控系统，由开鑫金服科技团队自主研发，供业界下载使用。开鑫金服科技团队期望通过这种开源的方式促进行业交流、发展，共同进步。 Talos以Google Dapper论文为理论基础，参照Twitter Brave的实现方案，面向当今互联网复杂的环境，基于客户端探针上报应用调用链相关日志，通过ElasticSearch引擎和HBase大数据存储技术，对海量请求进行实时链式跟踪、预警，能快速定位问题根源，有效保障了系统的稳定运行，提升了客户体验。 开鑫金服科技团队通过5年的磨砺，自主研发了多项先进的框架和平台。2017年12月24日，开鑫金服公司成立5周年，为迎接这有意义的一天，团队决定将Talos项目贡献给开普勒鑫球的开源社区；同时也期望更多的技术爱好者加入到开源社区中来，共同分享、交流。开普勒鑫球开源社区后续还会开源更多优质领先的项目，敬请期待！ 开源地址（或点击开普勒鑫球公众号菜单【开源项目】直接访问）：","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"如何设计一个大数据全链路监控系统","slug":"【纯干货分享】如何设计一个大数据全链路监控系统","date":"2017-12-15T15:07:13.000Z","updated":"2018-01-06T11:37:31.032Z","comments":true,"path":"2017/12/15/【纯干货分享】如何设计一个大数据全链路监控系统/","link":"","permalink":"http://kplxq.github.io/2017/12/15/【纯干货分享】如何设计一个大数据全链路监控系统/","excerpt":"纯干货分享！ 大数据全链路监控系统架构设计内部PPT来啦，赶紧保存。 后续开普勒鑫球还会陆续发布一系列文章逐一展开详细讲解，手把手教你，干货满满，敬请关注吧！","text":"纯干货分享！ 大数据全链路监控系统架构设计内部PPT来啦，赶紧保存。 后续开普勒鑫球还会陆续发布一系列文章逐一展开详细讲解，手把手教你，干货满满，敬请关注吧！","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"部署文档","slug":"部署文档","date":"2017-12-15T14:59:56.000Z","updated":"2017-12-22T10:00:06.488Z","comments":true,"path":"2017/12/15/部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/部署文档/","excerpt":"整体部署架构","text":"整体部署架构 部署节点数及基准配置 组件名称 组件类型 建议节点数 基准配置 搜索引擎(elastic search) 中间件 Elastic Search(3) cpu:2C memory:8G 分布式列存储数据库(Hbase) 中间件 CDH Manager(1) cpu:2C memory:4G disk:50G 分布式列存储数据库(Hbase) 中间件 Hbase MasterServer(1) cpu:2C memory:4G disk:50G 分布式列存储数据库(Hbase) 中间件 Hbase RegionServer(2) cpu:2C memory:4G disk:150G(留存30天数据) 分布式队列服务器(Kafka) 中间件 Kafka Server(3) cpu:2C memory:4G disk:20G 分布式配置管理服务器(zookeeper) 中间件 Zookeeper Server(3) cpu:2C memory:4G talos-storage 自有组件 2 cpu:2C memory:4G disk:20G talos-dashboard 自有组件 1 cpu:2C memory:4G disk:20G 部署步骤hosts配置在部署前请维护整个集群环境的hosts，并推送到每个部署节点 12345678910111213141516171819202122#es 集群192.168.99.101 es1192.168.99.102 es2192.168.99.103 es3# kafka集群192.168.99.104 kafka1 zk1192.168.99.105 kafka2 zk2192.168.99.106 kafka3 zk3# hbase集群192.168.99.107 hbase1192.168.99.108 hbase2192.168.99.109 hbase3192.168.99.110 cdhmaster# talos-dashboard192.168.99.111 talos-dashboard# talos-storage192.168.99.112 talos-storage1192.168.99.113 talos-storage2 中间件安装中间件版本信息如下: 中间件名称 版本 备注 搜索引擎 Elastic Search-2.4.0 3个节点 分布式列存储数据库 Hbase-1.2.0(CDH-5.8.0) 4个节点 CDH Manager(1) Hbase MasterServer() Hbase RegionServer(2) 分布式队列服务器 Kafka-2.11-0.10.0.1 3个节点 分布式文件系统 Hdfs-2.6.0(CDH-5.8.0) 内嵌至Hbase部署中 分布式配置管理服务器 Zookeeper-3.4.5(CDH-5.8.0) - Kafka1、中间件安装另附文档Kafka部署文档2、创建Talos系统在kafka集群所用的topic 配置如下： topic名称：talos-open-sourcepartition数目：1024replication数据：1 (无需备份) 脚本如下： 1./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1024 --topic talos-open-source Elasticsearch1、中间件安装另附文档Elasticsearch部署文档2、创建Talos系统elasticsearch索引 配置如下：index： talosmapping: trace刷新时间：5s分片数：5备份：0 123456789101112131415curl -XPOST http://es1:9200/talos -d &apos;&#123; &quot;settings&quot; : &#123; &quot;number_of_replicas&quot;: &quot;0&quot;, &quot;number_of_shards&quot;: &quot;5&quot;, &quot;refresh_interval&quot;: &quot;5s&quot; &#125;, &quot;mappings&quot; : &#123; &quot;trace&quot; : &#123; &quot;properties&quot; : &#123; &quot;traceid&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot; &#125;, &quot;contents&quot; : &#123; &quot;type&quot; : &quot;string&quot;&#125; &#125; &#125; &#125;&#125;&apos; HBase1、中间件安装参考HBase部署文档2、创建Talos系统Hbase表 配置如下：表名：tracerowkey: id （talos系统中的traceId)列族：span （talos系统中的不同的spanId即为该列族下的不同列）数据失效时间：30天 脚本如下（在hbase shell中执行）： 1create &apos;trace&apos;, &#123;NAME=&gt;&apos;id&apos;, TTL=&gt;&apos;2592000&apos;&#125;,&#123;NAME=&gt;&apos;span&apos;, TTL=&gt;&apos;2592000&apos;&#125; 系统自有组件安装talos-dashboard部署前请确认hosts已更新 1、下载talos-dashboard.war2、将talos-dashboard包放到tomcat/webapps路径下3、启动tomcat4、浏览器打开talos-dashboard，地址：http://talos-dashboard:8080/talos-dashboard/index.html 123cd /usr/share/tomcatwget https://gitee.com/lhldyf/talos-readme/raw/master/talos-dashboard.warservice tomcat start talos-storage部署前请确认hosts已更新 1、下载talos-storage.zip2、解压至/usr/share/talos-storage3、启动talos-storage 12345cd /tmpwget https://gitee.com/lhldyf/talos-readme/raw/master/talos-storage.zipunzip /tmp/talos-storage.zip -d /usr/sharecd /usr/share/talos-storagesh bin/start.sh;tailf logs/stdout.log","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Kafka部署文档","slug":"Kafka部署文档","date":"2017-12-15T13:01:57.000Z","updated":"2017-12-22T09:57:24.639Z","comments":true,"path":"2017/12/15/Kafka部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Kafka部署文档/","excerpt":"机器列表 节点 建议host Node1 kafka1 zk1 Node2 kafka2 zk2 Node3 kafka3 zk3","text":"机器列表 节点 建议host Node1 kafka1 zk1 Node2 kafka2 zk2 Node3 kafka3 zk3 逻辑拓扑 部署步骤组件下载Download KafkaDownload Zookeeper 下载链接若失效，请参考官网最新链接 KafkaZookeeper Zookeeper安装 将zookeeper解压缩到/opt/zookeeper目录下 cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg 修改配置文件: vim /opt/zookeeper/conf/zoo.cfg 文件末尾加上 1234autopurge.purgeInterval=1server.1 = kafka1:2888:3888server.2 = kafka2:2888:3888server.3 = kafka3:2888:3888 /opt/zookeeper/bin/zkServer.sh start 启动 zk Kafka安装1、 将kafka解压缩到/opt/kafka目录下2、 修改/opt/kafka/config/consumer.properties文件，将zookeeper.connect=127.0.0.1:2181改成zookeeper.connect=zk1:2181,zk2:2181,zk3:21813、修改/opt/kafka/config/producer.properties文件，将bootstrap.servers=localhost:9092改成bootstrap.servers=kafka1:9092,kafka2:9092,kafka3:90924、修改/opt/kafka/config/server.properties文件，修改以下key： 123broker.id=2 （2表示node2，node1就是1，node3就是3）listeners=PLAINTEXT://127.0.0.1:9092 （本机ip）zookeeper.connect=zk1:2181,zk2:2181,zk3:2181 5、在/tmp/zookeeper目录下，新建一个myid文件，内容是2（node2就写2， node3就写3，同broker.id）6、进入/opt/kafka/bin/目录执行 ./kafka-server-start.sh ../config/server.properties &amp; 启动kafka","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Elasticsearch部署文档","slug":"Elasticsearch部署文档","date":"2017-12-15T11:57:07.000Z","updated":"2017-12-22T09:57:29.471Z","comments":true,"path":"2017/12/15/Elasticsearch部署文档/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Elasticsearch部署文档/","excerpt":"机器列表 节点 建议host Node1 es1 Node2 es2 Node3 es3","text":"机器列表 节点 建议host Node1 es1 Node2 es2 Node3 es3 环境准备1、JDK1.7+ 节点部署官网有quick-start 注意：Elasticsearch 限制使用非root用户来进行以下操作，如创建用户es 1、下载Elasticsearch2.4.0的zip包2、解压elasticsearch至/usr/share路径3、修改配置文件config/elasticsearch.yml 12345678910111213141516171819202122# es 集群名称，同一个集群名称需一致cluster.name: es-talos# es节点名称，每个节点设置不同，三个节点1/2/3即可node.name: node-1# 节点rack，每个节点设置不同，三个节点1/2/3即可node.rack: r1path.logs: /usr/share/elasticsearch-2.4.0/logs# 节点host，本机host即可network.host: es1http.port: 9200 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; # 集群部署的另外两个节点discovery.zen.ping.unicast.hosts: [&quot;es2&quot;,&quot;es3&quot;]discovery.zen.minimum_master_nodes: 2# 默认index刷新间隔 index.refresh_interval: 120s# 默认数据副本数index.number_of_replicas: 0# 设置脚本可执行script.inline: true script.indexed: true 4、修改elasticsearch jvm内存大小,建议值为本机物理内存/2修改文件install_path/bin/elasticsearch.in.sh文件中第16行及19行,设置ES_MIN_MEM=物理内存/2(16行)、ES_MAX_MEM=物理内存/2(19)行 5、解压后，使用es用户进行到bin目录下进行启动 1./elasticsearch -d 6、浏览器访问 es1:9200，看到如下响应则启动成功 123456789101112&#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;es-talos&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.4.0&quot;, &quot;build_hash&quot; : &quot;ce9f0c7394dee074091dd1bc4e9469251181fc55&quot;, &quot;build_timestamp&quot; : &quot;2016-08-29T09:14:17Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.2&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 以上1-6步骤在三个节点上操作完成，并都能看到启动成功的响应，则部署成功。 ES监控插件部署1、 如果在有网络的情况下可以直接执行/usr/share/elasticsearch2.4.0/bin/plugin install mobz/elasticsearch-head2、 如果服务器没有连网下载elasticsearch-head3、 可以通过web服务器打开，如将elasticsearch-head放到tomcat的里面，通过tomcat访问http://es1:8080/elasticsearch-head-master/index.html 部署成功如图：","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"Talos接入使用说明","slug":"Talos接入使用说明","date":"2017-12-15T11:14:07.000Z","updated":"2017-12-22T10:03:55.924Z","comments":true,"path":"2017/12/15/Talos接入使用说明/","link":"","permalink":"http://kplxq.github.io/2017/12/15/Talos接入使用说明/","excerpt":"运行环境开发环境开发环境需要： JDK1.7+ Maven3.1+","text":"运行环境开发环境开发环境需要： JDK1.7+ Maven3.1+ 依赖引入12345&lt;dependency&gt; &lt;groupId&gt;com.kxjf.talos&lt;/groupId&gt; &lt;artifactId&gt;talos-interceptor&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 使用说明这里对一些配置进行解释说明，范例代码移步talos-sample 配置说明必选配置Talos实例化Spring配置Talos实例，配置说明：1、 serviceName：用于区分集群应用，需唯一，建议取机器host2、 collector ：数据收集的实现方法，默认使用日志收集方式，需额外配置logback，系统目前提供这一种收集方式，可自行实现 参考配置： 12345&lt;bean id=&quot;talos&quot; class=&quot;com.kxd.talos.trace.core.Talos&quot;&gt; &lt;constructor-arg type=&quot;String&quot; value=&quot;talos-sample&quot; /&gt; &lt;constructor-arg type=&quot;float&quot; value=&quot;1.0f&quot; /&gt; &lt;constructor-arg ref=&quot;loggingSpanCollector&quot; /&gt;&lt;/bean&gt; logback配置配置logback.xml，需增加trace collector的日志输出配置，有几个自定义的环境配置，说明如下：1、 KAFKA_TOPIC_NAME: kafka推送的topic名称，用于接收日志数据2、 KAFKA_BOOTSTRAP_SERVERS ： kafka集群节点配置，” ip1:port1,ip2:port2…” 的方式配置即可。参考如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;appender name=&quot;talosTraceCollectorFileAppender&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--日志文件输出的文件名 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/$&#123;TALOS_TRACE_LOG_FILE&#125; &lt;/fileNamePattern&gt; &lt;!--日志文件保留天数 --&gt; &lt;MaxHistory&gt;$&#123;LOG_SAVE_DAYS&#125;&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;%msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;appender name=&quot;talosKafkaAppender&quot; class=&quot;com.github.danielwegener.logback.kafka.KafkaAppender&quot;&gt; &lt;encoderclass=&quot;com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt; %msg&lt;/pattern&gt; &lt;/layout&gt; &lt;/encoder&gt; &lt;topic&gt;$&#123;KAFKA_TOPIC_NAME&#125;&lt;/topic&gt; &lt;keyingStrategyclass=&quot;com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy&quot; /&gt; &lt;deliveryStrategyclass=&quot;com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy&quot; /&gt;&lt;producerConfig&gt;bootstrap.servers=$&#123;KAFKA_BOOTSTRAP_SERVERS&#125; &lt;/producerConfig&gt; &lt;!-- this is the fallback appender if kafka is not available. --&gt; &lt;appender-ref ref=&quot;talosTraceCollectorAppender&quot; /&gt;&lt;/appender&gt;&lt;appender name=&quot;asyncTalosKafkaAppender&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;appender-ref ref=&quot;talosKafkaAppender&quot; /&gt;&lt;/appender&gt;&lt;logger name=&quot;com.kxd.talos.trace.core.collector&quot; level=&quot;ALL&quot; additivity=&quot;true&quot;&gt; &lt;appender-ref ref=&quot;asyncTalosKafkaAppender&quot; /&gt; &lt;appender-ref ref=&quot;talosTraceCollectorFileAppender&quot; /&gt;&lt;/logger&gt; 配置logback.properties，参考如下： 123TALOS_TRACE_LOG_FILE=talos-trace_%d&#123;yyyy-MM-dd&#125;.logKAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092,kafka3:9092KAFKA_TOPIC_NAME=talos-open-source Web应用配置TalosServletFilterSpring配置TalosServletFilter实例，初始化配置filter中的Talos实例，参考如下： 123456&lt;bean id=&quot;httpServerServletFilter&quot; class=&quot;com.kxd.talos.trace.interceptor.server.http.TalosServletFilter&quot;&gt; &lt;property name=&quot;talos&quot; ref=&quot;talos&quot; /&gt; &lt;!-- 配置需要过滤的url,可使用*进行匹配,如有多个,用英文逗号(,)分割 --&gt; &lt;property name=&quot;patterns&quot; value=&quot;/**&quot; /&gt;&lt;/bean&gt; web.xml中增加配置，使用代理模式，参考如下： 12345678910111213141516&lt;filter&gt; &lt;filter-name&gt;TraceFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;targetBeanName&lt;/param-name&gt; &lt;param-value&gt;httpServerServletFilter&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;TraceFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 多线程配置使用约束：1、 多线程使用线程池方式(ThreadPoolExecutor)，不得使用new Thread()模式生成新线程2、 多线程方法必须实现Runable或Callable接口。Talos对spring 线程池ThreadPoolTaskExecutor 做了一层额外封装，收集多线程的相关数据，在使用多线程定义线程池时，额外实例化该类实例，执行线程池方法时，使用该实例，参考如下： 12345&lt;bean id=&quot;talosExecutorService&quot; class=&quot;com.kxd.talos.trace.core.concurrent.TalosSpringThreadPool&quot;&gt; &lt;constructor-arg ref=&quot;threadPoolExecutor&quot; /&gt; &lt;constructor-arg ref=&quot;talos&quot; /&gt;&lt;/bean&gt; 自定义采集配置自定义采集如果需要使用callback模式，需要配置callback的模板如下： TalosCallbackTemplateAOP的拦截有一定的限制性，对于一些无法进行AOP切面拦截的方法入口，如果有采集数据的必要性，Talos提供了callback模式的采集方式，需要新增的配置如下: 123&lt;bean id=&quot;talosCallbackTemplate&quot; class=&quot;com.kxd.talos.core.trace.TalosCallbackTemplate&quot;&gt; &lt;property name=&quot;talos&quot; ref=&quot;talos&quot;/&gt;&lt;/bean&gt; 数据采集说明自定义采集Talos提供两种自定义的数据采集方式,以下两种方式二选一即可 example: 123private void step3() &#123; aopServiceB.step4(); &#125; 这是现有的一个方法，无法通过AOP拦截，但又有数据采集的必要性，Talos系统提供两种实现方案，以下逐一说明： 方案一注入talos，通过start方法和finish方法完成数据采集，注意需要将方法用try..catch捕获异常，并在finally语句中做finish操作。 12345678910111213141516171819@Autowiredprivate Talos talos;private void step3() &#123; Span startSpan = talos.start(&quot;AopServiceA.step3&quot;); try &#123; aopServiceB.step4(); &#125; catch (AppException ae) &#123; startSpan.setExType(&quot;A&quot;); startSpan.setErrorCode(ae.getErrorCode()); throw ae; &#125; catch (Throwable t) &#123; startSpan.setExType(&quot;T&quot;); startSpan.setErrorCode(ErrorCode.ERROR_SERVICE_INTERCEPTOR_INVOKE); throw t; &#125; finally &#123; talos.finish(startSpan); &#125;&#125; 方案二注入TalosCallbackTemplate实例，将原有方法放在TalosCallback的execute方法即可。 123456789101112@Autowiredprivate TalosCallbackTemplate template;private void step3() &#123; template.execute(null, new TalosCallback()&#123; @Override public Object execute(Object request) &#123; aopServiceB.step4(); return null; &#125; &#125; );&#125; 业务数据采集注:为保证可在海量数据中对指定业务调用链进行搜索,建议每个业务均应当进行业务数据的采集,且该业务数据应当可唯一标识某次业务调用 为了更加易于检索出请求链路，业务人员必须在一个调用链中硬编码的方式写入一些业务数据。API为Talos.collect(String key, String value), 相关原则如下： 1、key 为英文字母组成，驼峰命名，需能根据该值知晓其代表的含义，比如userName, userId等。 2、value 长度不超过100，参数值确保可以方便的搜索出唯一一条调用链，或通过多个参数值确认一条调用链。参考使用如下： 1234public void withParam(ParamDto paramDto) &#123; Talos.collect(&quot;userName&quot;, paramDto.getUserName()); aopServiceB.step1();&#125; 多线程数据采集通过Spring注入TalosSpringThreadPool的实例，使用方法参考ThreadPoolTaskExecutor，参考如下： 1234567891011121314151617@Autowiredprivate TalosSpringThreadPool talosExecutorService;public void call2thread() &#123; talosExecutorService.submit(callableService); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; talosExecutorService.submit(callableService2); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;","categories":[],"tags":[{"name":"talos","slug":"talos","permalink":"http://kplxq.github.io/tags/talos/"}],"keywords":[]},{"title":"单元测试中mock框架的简单使用","slug":"单元测试中mock框架的简单使用","date":"2016-07-31T08:24:05.000Z","updated":"2018-01-16T09:18:11.693Z","comments":true,"path":"2016/07/31/单元测试中mock框架的简单使用/","link":"","permalink":"http://kplxq.github.io/2016/07/31/单元测试中mock框架的简单使用/","excerpt":"为什么要单元测试： 帮助理解需求：开发人员在编写测试代码的时候，可以更加清楚的了解代码的结构和业务逻辑。 尽早的发现bug：在&lt;快速软件开发&gt;这本书中指出，根据大量的研究数据证明：最后才修改一个bug的代价是在bug产生时修改它的代价大10倍。 提高局部代码的质量：保证局部代码质量，我们才能保证各个依赖你的其他模块的代码质量。 成本：这里说的测试成本是相对而言的，比如:对于集成测试的复杂环境部署，单元测试显得相对简单点。笔者简单了解了下笔者公司的开发写个单元测试平均在0.5H左右。 单元测试可以被复用：一劳永逸。一些固化的功能模块，只要我们写好单元测试后，以后基本不需要调整，为实现单元测试自动化打好了基础。","text":"为什么要单元测试： 帮助理解需求：开发人员在编写测试代码的时候，可以更加清楚的了解代码的结构和业务逻辑。 尽早的发现bug：在&lt;快速软件开发&gt;这本书中指出，根据大量的研究数据证明：最后才修改一个bug的代价是在bug产生时修改它的代价大10倍。 提高局部代码的质量：保证局部代码质量，我们才能保证各个依赖你的其他模块的代码质量。 成本：这里说的测试成本是相对而言的，比如:对于集成测试的复杂环境部署，单元测试显得相对简单点。笔者简单了解了下笔者公司的开发写个单元测试平均在0.5H左右。 单元测试可以被复用：一劳永逸。一些固化的功能模块，只要我们写好单元测试后，以后基本不需要调整，为实现单元测试自动化打好了基础。 当前单元测试遇到的问题：本地测试代价大：笔者所在公司有将近10个系统，有时候开发一个简单的功能，如果不发布到集成环境测试，在本地做单元测试至少需要启动2-3个系统才可以跑起来，经常IDE卡死。而发布到集成环境测试则耗时较长且调式麻烦。 复杂性：开发需要关心各种环境配置项的值，才可以正确的启动系统做单元测试，如：证书、密钥、验签等安全配置。特别是像笔者所在的这种金融领域，各种安全配置、银行调用URL配置。 不可控性：跨公司、跨部门、跨系统的接口调用，导致单元测试的效率和结果不可控。 异常分支测试：笔者做的金融系统，有很多和银行交互的接口，有的时候需要连接一下银行的测试环境测试下“难于上青天啊”(小银行会简单的配合你下，大银行根本不鸟你，给你一个地址你自己玩去吧)，更别说给你返回个异常数据了，连正常的数据都返回不了。另外比如：并发、系统压力测试(有的时候会选择硬编码将调用外部系统的地方写死，压力测试后再改回来上线，但是容易漏改、耗费人力、不能复用)，还有当前很流行的各种分布式、大数据的单元测试都比较困难。 常见的解决方案下面笔者简单分析下上述问题常见的解决方案(可能有更好的方案，这里笔者还没有想到,可以一起交流学习)： 问题1-solve. 部署一套稳定的环境：专门给开发人员单元测试连接调用，但是也存在一些问题，比如我们经常发现使用dubbo这样的RPC调用框架，会出现消费者和服务者混乱，因为共用一套环境大家都把自己的服务注册上去了。数据库数据会被别的开发修改，调式半天发现数据被别的开发修改了，这种情况痛苦的一比。 最理想的是一人一套环境，只有财大气粗的公司如此了。 问题2-solve. 统一开发目录和配置项：对于安全配置的证书这些问题比较好解决，所有开发共用一套单元测试环境变量配置，证书路径和url都统一。不同操作系统不同模板 问题3-solve. 万年难：问题三这个就比较难搞定了，例如你正在测试自己的case，突然你调用的B部门的服务出问题了，你会经常听到类似：我擦，服务被关闭了？他们在发布新版本？返回的数据不对啊、怎么用户不存在？我靠，他们又刷库了？。一等就是千万年，无法忍受。 当然笔者也曾经试着将这些接口调用全部写死了。直接new一个结果返回，然而细 心的人提交代码的时候可能会检查下，不细心的则深挖坑啊。。。。。。 问题4-solve. 写死返回结果：在需要异常场景的时候，注释掉调用代码，写死返回结果。基本和3类似。 后来基于3和4的解决思路，慢慢的就演变出了一种专门解决这些场景的框架：Mock框架。这也符合笔者一直崇尚的理念：**业务驱动开发，有需求就会诞生解决方案**。 Mock框架初接触笔者这里简单的说下自己的mock实现，如果有不足的地方还希望各路大神多多指教，相互学习成长。 选择TestNG: 首先做单元测试当然少不了junit或者testng了(也有NB的公司有自己的测试框架，这些公司呢想必也都是业务驱动逼迫自己去搞的)，笔者这里就不阐述着两个测试框架的区别了，网上各种帖子，总之适合自己、用的熟练、懂得原理就可以。那笔者这里选择的是testng。 选择Jmockit作为mock框架：另外一个就是mock框架的选型。当前的江湖中，mock框架已经有很多门派了，但是万变不离其宗，他们要么是JDK的动态代理、要不就是CGLIB的动态代理生成新的类。比如：easymock 、mockito、jmock等已经风生水起了，但是笔者认为这样的实现原理决定了它的局限性，比如：final方法、构造方法、不能被覆写的方法这些就不能被mock了。 思路到这里暂停一些，我们来回忆下最初的我们： 记得很多年前，我们在刚学java的时候，大神们就教导我们学习java，首先我们得知道一个java文件是怎么最终被机器执行的。 我们写了一个Hello.java 然后通过cmd命令javac Hello.java经过javac的编译器后完成了对代码的词法分析、语法分析、抽象语法树，然后得到一个Hello.class,这部分是在JVM外面的完成的。 然后由JVM类加载到内存中(这里笔者就不叙述加载的过程了，网上可以搜到很多相关文章，再说笔者自己了解的也是皮毛)。到JVM以后，然后JVM翻译成机器码执行。 有了这样的背景知识，再让我们思考如何mock一个类，我们自然的会想到的去修改这个类中在JVM中的字节码，这样就没有什么不可以mock的了。我们知道从JDK1.5开始就提供了java.lang.instrument包，其中提供了修改JVM中已加载类的重定义入口即java.lang.instrument.Instrumentation#redefineClasses(ClassDefinition...)方法。 那当前江湖中有没有这样的一个框架可以和我们的思路很符合呢？笔者google到了这样的一种框架，那就是JMockit(笔者一直认为框架只要适合自己能够满足业务场景就好，无需过多的去追求时髦)。 Jmockit简单介绍： JMockit：是googlecode上的一个项目衍生而来，现在已经有了自己的独立门户网站，官网介绍其是基于asm库来修改java的字节码从而达到篡改类的行为的mock工具。通过JDK提供的类重定义方法：java.lang.instrument.Instrumentation#redefineClasses(ClassDefinition…)作为修改JVM中类的定义的入口。 这样mock框架就定了。是时候我们设计下我们蓝图了。 融合TestNG和JMockit 框架设计： AbstractMockBase：mock类的基类，为以后扩展预留。 TestAMock: 具体的Mock实现类。 mockContext.xml：所有的mock类集中于xml中进行管理，然后写了一个JMockitBeanFactory加载这些类。方便以后统计、修改。 JMockitBase：所有需要用到mock的单元测试类继承此类，提供getMockBean方法。 AbstractDataProvider：提供从xml读取单元测试源数据入口。 TestNGIInvokedMethodListener：testng中的IInvokedMethodListener监听接口实现，完成MockInfo注解的实现。 注：JMockit是通过类TestNGRunnerDecorator实现Testng的两个接口：IInvokedMethodListener，IExecutionListener来实现和TestNG交互的.。 另外我们mock spring容器中bean的时候，一定要拿到被代理前的原始类。方法如下： 编码实战版本 Testng：6.8 Jmockit：1.21 其他的Spring依赖各位随意吧. 场景一: mock原有的接口返回 笔者这里以金融系统中查询工作日这样的接口举例，通常这种查询我们都会调用一个单独的统一辅助系统去查询某天是否是工作日，然后依次来判断下一步的逻辑。但是笔者希望他永远返回是工作日，且不用配置远程调用的任何信息。(最直接的就是在调用出修改代码，写死返回值，这样虽然可以解决问题但是就像前面笔者说的，复用性不强且容易出问题) 下面笔者列举出Mock主要的代码实现,完整代码笔者会稍后上传到github上。 a. 工作日查询接口 b. 工作日查询接口实现编写WorkDayAssistant的mock类:空父类，以后扩展用 Mock类(类的部分mock)(Jmock分类局部mock和全部mock)基金购买接口基金购买接口实现 c. 自定义MockInfo注解-用于定义当前test method 运行时需要哪些bean被mock 运行测试 运行结果： 场景二: 从xml获取数据源 对于一些模块和功能已经固化的代码，我们希望用固定的数据在每个迭代版本中都可以得到固定的结果，笔者这里拿金融系统中常见的绑卡场景为例。 定义xml格式 DataProvider编写 数据获取使用(这里取数据比较恶心，要从map中get，笔者计划有时间改成JavaBean字段映射) 运行结果： 然已经取到数据了，那后面的测试和结果校验随意吧。 总结：当前笔者只是简单介绍了框架的简单使用和集成，后续笔者将抽时间将Jmockit的原理、详细使用方法、当期框架设计优化改进的地方再发表出来和大家一起学习交流。 作者：猎狐，就职于开鑫金服，主要负责Java Web方向的开发工作。","categories":[],"tags":[{"name":"mock框架","slug":"mock框架","permalink":"http://kplxq.github.io/tags/mock框架/"}],"keywords":[]},{"title":"React一小时入门","slug":"React一小时入门","date":"2016-07-27T08:23:36.000Z","updated":"2018-01-16T09:18:28.180Z","comments":true,"path":"2016/07/27/React一小时入门/","link":"","permalink":"http://kplxq.github.io/2016/07/27/React一小时入门/","excerpt":"React是Facebook开发的js库，不仅影响了其他前端库的开发思路，而且还引申出React Native等技术，在开源世界引起了极大的反响。 Facebook为什么要花费大量的精力开发React，为了解决什么问题，以及如何解决问题，我们将就这些问题做一些简单的讨论和学习。","text":"React是Facebook开发的js库，不仅影响了其他前端库的开发思路，而且还引申出React Native等技术，在开源世界引起了极大的反响。 Facebook为什么要花费大量的精力开发React，为了解决什么问题，以及如何解决问题，我们将就这些问题做一些简单的讨论和学习。 React背景Facebook在开发广告系统时发现，因为他们非常庞大的代码库，导致前端的MVC架构非常复杂难以维护。每当开发新需求时，系统复杂度成倍增长，代码非常脆弱且执行结果不可预测。所以Facebook认为MVC架构不适合开发大规模的前端应用，其中很重要的原因是应用中的模型（M）和视图（V）之间的双向数据绑定导致前端代码复杂度迅速提高，难以理解和调试，极大地影响Facebook的开发效率。 Facebook给出的解决方案就是React。React在Facebook内部已经试用了多年，效果很好。React另辟蹊径解决前端代码复杂度高的问题，JSX语法甚至被初学者认为不伦不类。但是我在尝试了React之后，我无法自拔地喜欢上了这种单向数据驱动的开发思路。 那么React是解决什么问题的呢，Facebook官网上介绍说： We built React to solve one problem: building large applications with data that changes over time. 即React是用来构建那些数据会随时改变的大型应用。为了构建大型应用，React有两个主要的特点： 简洁代码里非常简单的描述在每个时间点应用应该呈现的样子。当应用数据改变时，React会自动管理UI界面。 声明式当数据发生改变时，React表现的是刷新DOM树。但事实上React仅仅更新发生了变化的那一部分。我们要做的就是构建组件（Component），封装组件。React自动管理组件的生命周期。 React特性React有三大特性：组件化、虚拟DOM和单向数据流。这三大特性是React运行的基础，并且由虚拟DOM衍生出React Native项目。 组件化React允许将代码封装成组件（Component），然后像插入普通HTML标签一样，在页面中插入这个组件(源码参见：https://github.com/xeostream/react-demo/blob/master/helloworld.html)。 上述代码中，变量HelloMessage就是一个组件类。所有的组件类必须有render方法，用于输出组件内容。 组件的用法与原生的HTML标签完全一致，可以任意加入属性。比如，就是在HelloMessage组件中加入message属性，值为“yo，what’up,man?”。组件内部可以通过this.props对象获取组件的属性，this.props.message就是取message属性值。上面代码的运行结果如下。 组件化的最显著特征就是万物皆由组件构成，那么多个组件之间相互通信就是很大的问题。一般解决方式有三种： 使用props，构建通信链 在组件初始化时，保存组件的句柄。在其他组件中使用句柄达到直接访问组件的目的，完成通信 使用PubSub模式 首先第一种方法容易理解，但是在组件嵌套较深的情况下，为达到通信的目的，组件之间相互调用而且组件需要冗余许多不需要的props，不太适合；第二种方法避免了第一种方法的问题，但是需要维护很多变量，也不是非常好的方案；对于第三种方法，PubSub模式有助于组件解耦和代码组织，而且PubSub有很多开源实现。建议组件间通信使用PubSub模式。 虚拟DOM当组件状态改变的时候，React会自动调用组件的render方法重新渲染整个组件的UI。 但是如果这样大面积的操作DOM，性能会是一个很大的问题，所以React实现了虚拟DOM。 虚拟DOM是一个纯粹的JS数据结构，存到内存中，性能很快。React将组件的DOM结构映射到虚拟DOM上，在虚拟DOM上实现了一个高效的diff算法。所以每次当组件的数据更新时，React会通过diff算法找到需要更新的DOM节点，再把修改更新到浏览器实际的DOM节点上。 单向数据流 单向数据流是React推崇的一种应用架构的方式。在React的组件中，我们监听状态的变化，并在组件的声明周期函数里对组件状态做一个的响应和操作，即页面的变化只与状态数据的变更有关。这里展示一种官方的单向数据流实现： （注：Flux由单向数据流扩展而来，React与Flux相互独立，React仅实现Flux架构中的View部分。当然也可以使用其他js库实现这个View。） 这里我们将React组件理解为一个状态机，状态机内部的状态发生了改变，则对外的输出也会发生改变，两者之间的关系是一一对应的，即如果组件的状态数据是确定的话，则组件的输出也是确定的。这点对于前端的测试和DEBUG是非常大的帮助，对减少前端BUG是很有好处的。 我开始不太理解单向数据流的概念，因为搞不清楚单向数据流和MVC的关系。其实单向数据流并不是和MVC在同一层次对系统的抽象，单向数据流表达的是MVC中View和Model之间数据的传递方式。所以这个问题更精确的表达应该是单向数据流和双向数据流之间的对比。 双向数据流常见于Angular1.x等库中，指Model和View可以相互传递数据，且多个Model和View之间传递没有限制，其中传递是代码不需要显式设置监听事件以同步数据，而是Model和View相互绑定。 所以双向数据流的优势是容易理解，在简单系统中开发非常方便；但是缺点是在复杂工程中，多个Model和View之间绑定，保持这种绑定关系极耗性能，经常会导致View无响应，性能急剧下降，而且因为存在多层绑定关系，导致View的Debug几乎不可能。基于以上原因，很多前端框架如angular2.0已经开始将单向数据流作为默认的绑定方式。 React原理上面一直在说React是要解决什么问题的，现在说下React是怎么解决这些问题的？ 传统的web应用，操作DOM一般是直接更新操作或者是大面积页面刷新，这种操作是比较昂贵的。React为了尽量减少对DOM的操作，提供了一种与众不同的方式来更新DOM。就是DOM层之前增加一个轻量级的虚拟DOM，虚拟DOM是React抽象出来的描述真实DOM结构的对象，由虚拟DOM管理真实DOM的更新。 虚拟DOM为保证高效的更新真实DOM，在更新之前增加diff算法计算出真实DOM的最小变更。 在真实DOM树上的节点被称为元素，在虚拟DOM里被称为组件。组件是非常重要的，虚拟DOM是由组件组成。 component 的使用在 React 里极为重要, 因为 components 的存在让计算 DOM diff 更高效。 state、props和render在组件中是非常重要的属性。state、props属性包含定义组件需要的数据。state表示组件当前的状态，当state发生变化时，组件会调用render方法重新渲染。相对于state，props是组件初始化需要的数据，React规约props在组件的生命周期内无法更改也不应改变。 在组件的生命周期中，随着该组件的props和state发生改变，组件的DOM表现也会有相应的变化。一个组件即是一个状态机，对于特定地输入，组件总返回一致的输出。 组件的生命周期可以分为三大过程。分别为： mounted组件被渲染为真实的DOM元素插入浏览器的DOM结构的一个过程。 update已经处于mounted状态的组件被重新渲染的过程。 unmounted处于mounted状态的组件被从浏览器DOM结构中移除的过程。 组件的完整生命周期如下： 在组件的生命周期中有几个比较重要的方法： getDefaultProps此方法返回的对象可以用于设置默认的props值。 getInitialState此方法用来初始化组件实例的state，在这个方法里可以访问组件的props变量。 componentWillMount此方法在组件首次渲染之前调用，是在调用render方法之前最后一次修改组件的机会。 render此方法会创建一个虚拟DOM，用来表示组件的输出。在组件中，render方法是必须的方法。render方法本身需要满足几点： 只能通过this.props和this.state访问组件的数据 可以返回null，false或者任何React组件 返回结果只能有一个顶级组件，不能返回一组元素 componentDidMount此方法在render方法执行之后被调用，所以在方法中可以获取组件在真实DOM的节点。 shouldComponentUpdate此方法决定组件是否重新渲染，如果方法返回结果为false的话，则组件不会调用render方法重新渲染。 componentWillUpdate此方法和componentWillMount类似，渲染后的组件在接收到新的props或者state改变之后，组件会调用此方法。 componentDidUpdate组件因接收到新的props或者state改变导致的重新渲染之后，会调用此方法，所以可以在方法中访问或者修改真实DOM。 componentWillUnmount当组件从DOM中卸载后销毁，会调用此方法完成所有的清理和销毁工作。在conponentDidMount中添加的任务都需要在此方法中销毁，比如创建的定时器和事件监听器。 React示例计时器 github源码 执行结果（原本想做个GIF，然而并不会做。。。）： React体验 使用单向数据流可以很好的隔绝业务，大大降低了单元测试的难度。 尽量将React组件（Component）做到小，做到细，也就是尽量拆分React组件。 基于数据驱动的方式开发，虽然开始的时候不容易理解，但确实可以减少前端的BUG。 React更适合数据驱动的项目，不太适应交互比较多的项目。 作者：王建双，就职于开鑫贷，主要负责Java Web方向的开发工作，也会根据兴趣涉猎前端相关的开发技术。目前在学习React和React Native、Spring高级特性。本人水平有限，欢迎各路大神就本文观点和出现的错误进一步的讨论。","categories":[],"tags":[{"name":"React","slug":"React","permalink":"http://kplxq.github.io/tags/React/"}],"keywords":[]}]}